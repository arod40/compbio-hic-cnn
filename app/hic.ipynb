{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring HIC contact matrices similarity with Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "        Based on https://github.com/pytorch/examples/tree/main/siamese_network\n",
    "        Siamese network for image similarity estimation.\n",
    "        The network is composed of two identical networks, one for each input.\n",
    "        The output of each network is concatenated and passed to a linear layer. \n",
    "        The output of the linear layer passed through a sigmoid function.\n",
    "        `\"FaceNet\" <https://arxiv.org/pdf/1503.03832.pdf>`_ is a variant of the Siamese network.\n",
    "        This implementation varies from FaceNet as we use the `ResNet-18` model from\n",
    "        `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_ as our feature extractor.\n",
    "        In addition, we aren't using `TripletLoss`, `BCELoss` can do the trick.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        self.encoder, encoded_features = self.build_encoder(input_size)\n",
    "\n",
    "        # add linear layers to compare between the features of the two images\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(encoded_features * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # initialize the weights\n",
    "        self.encoder.apply(self.init_weights)\n",
    "        self.fc.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "    def build_encoder(self, input_size, **kwargs):\n",
    "       raise NotImplementedError()\n",
    "\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.encoder(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # get two images' features\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "\n",
    "        # concatenate both images' features\n",
    "        output = torch.cat((output1, output2), 1)\n",
    "\n",
    "        # pass the concatenation to the linear layers\n",
    "        output = self.fc(output)\n",
    "\n",
    "        # pass the out of the linear layers to sigmoid layer\n",
    "        output = self.sigmoid(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class SiameseNetworkResnetEncoder(SiameseNetwork):\n",
    "    def __init__(self, input_size):\n",
    "        super(SiameseNetworkResnetEncoder, self).__init__(input_size)\n",
    "\n",
    "\n",
    "    def build_encoder(self, input_size):\n",
    "        # get resnet model\n",
    "        resnet = torchvision.models.resnet18(pretrained=False)\n",
    "\n",
    "        # over-write the first conv layer to be able to read HIC images\n",
    "        # as resnet18 reads (3,x,x) where 3 is RGB channels\n",
    "        # whereas HIC has (1,x,x) where 1 is a gray-scale channel\n",
    "        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        # remove the last layer of resnet18 (linear layer which is before avgpool layer)\n",
    "        resnet = torch.nn.Sequential(*(list(resnet.children())[:-1]))\n",
    "\n",
    "        return resnet, resnet(torch.rand(1, 1, *input_size)).shape[1]\n",
    "\n",
    "class SiameseNetworkLinearEncoder(SiameseNetwork):\n",
    "    def __init__(self, input_size):\n",
    "        super(SiameseNetworkLinearEncoder, self).__init__(input_size)\n",
    "\n",
    "    def build_encoder(self, input_size):\n",
    "        return nn.Linear(input_size[0] * input_size[1], 256), 256\n",
    "     \n",
    "    def forward_once(self, x):\n",
    "        output = self.encoder(x.view(x.size()[0], -1))\n",
    "        return output\n",
    "    \n",
    "class SiameseNetworkLeNetEncoder(SiameseNetwork):\n",
    "    def __init__(self, input_size):\n",
    "        super(SiameseNetworkLeNetEncoder, self).__init__(input_size)\n",
    "\n",
    "    def build_encoder(self, input_size):\n",
    "        encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "\n",
    "        return encoder, torch.prod(torch.tensor(encoder(torch.rand(1, 1, *input_size)).shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below find the implementation of the dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "class HICPairsBioReplicatesDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir: str,\n",
    "        bio_replicates_pairs: List[Tuple[str]],\n",
    "        non_bio_replicates_pairs: List[Tuple[str]],\n",
    "        chromosomes: List[str],\n",
    "    ):\n",
    "        self.root_dir = Path(root_dir)\n",
    "\n",
    "        print(\"Building positive image pairs\")\n",
    "        self.positive_pairs = self.__build_image_pairs(\n",
    "            bio_replicates_pairs, chromosomes\n",
    "        )\n",
    "\n",
    "        print(\"Building negative image pairs\")\n",
    "        self.negative_pairs = self.__build_image_pairs(\n",
    "            non_bio_replicates_pairs, chromosomes\n",
    "        )\n",
    "\n",
    "        self.all_pairs = self.negative_pairs + self.positive_pairs\n",
    "\n",
    "        self.transform = T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __build_image_pairs(self, pairs: List[Tuple[str]], chromosomes: List[str]):\n",
    "        img_pairs = []\n",
    "        for exp1, exp2 in pairs:\n",
    "            print(f\"Building image pairs for {exp1} and {exp2}\")\n",
    "\n",
    "            dir1, dir2 = Path(self.root_dir / exp1), Path(self.root_dir / exp2)\n",
    "            assert dir1.exists() and dir2.exists(), f\"{dir1} or {dir2} does not exist\"\n",
    "\n",
    "            if chromosomes is None:\n",
    "                chromosomes = set(p.name for p in dir1.iterdir()).intersection(\n",
    "                    set(p.name for p in dir2.iterdir())\n",
    "                )\n",
    "\n",
    "            for chr in tqdm(chromosomes):\n",
    "\n",
    "                chr_dir1, chr_dir2 = dir1 / chr, dir2 / chr\n",
    "                assert (\n",
    "                    chr_dir1.exists() and chr_dir2.exists()\n",
    "                ), f\"{chr_dir1} or {chr_dir2} does not exist\"\n",
    "\n",
    "                dir1_imgs, dir2_imgs = set(p.name for p in chr_dir1.iterdir()), set(\n",
    "                    p.name for p in chr_dir2.iterdir()\n",
    "                )\n",
    "\n",
    "                for img_name in dir1_imgs.intersection(dir2_imgs):\n",
    "                    img_pairs.append((chr_dir1 / img_name, chr_dir2 / img_name))\n",
    "\n",
    "        return img_pairs\n",
    "\n",
    "    def __get_extra_info(self, path):\n",
    "        return {\n",
    "            \"experiment\": path.parent.parent.name,\n",
    "            \"window\": tuple(map(int, path.stem.split(\".\"))),\n",
    "            \"chr\": path.parent.name,\n",
    "            \"path\": str(path)\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        src_img1, src_img2 = self.all_pairs[index]\n",
    "        img1, img2 = self.transform(Image.open(src_img1)), self.transform(Image.open(src_img2))\n",
    "        return {\n",
    "            \"input1\": img1,\n",
    "            \"input2\": img2,\n",
    "            \"label\": torch.tensor([0 if index < len(self.negative_pairs) else 1], dtype=torch.float32),\n",
    "            \"extra1\": self.__get_extra_info(src_img1),\n",
    "            \"extra2\": self.__get_extra_info(src_img2),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_pairs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the training procedures and util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import ConcatDataset, random_split\n",
    "import pandas as pd\n",
    "\n",
    "exp_name = \"hic_dataset-40x40-5k-VC_SQRT\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_path = \"../data/\" + exp_name\n",
    "\n",
    "experiment_to_cell_type = {\n",
    "    \"GSM1551552_HIC003\": \"GM12878\",\n",
    "    \"GSM1551554_HIC005\": \"GM12878\",\n",
    "    \"GSM1551569_HIC020\": \"GM12878\",\n",
    "    \"GSM1551599_HIC050\": \"IMR90\",\n",
    "    \"GSM1551600_HIC051\": \"IMR90\",\n",
    "    \"GSM1551604_HIC055\": \"IMR90\",\n",
    "    \"GSM1551607_HIC058\": \"HMEC\",\n",
    "    \"GSM1551608_HIC059\": \"HMEC\",\n",
    "    \"GSM1551609_HIC060\": \"HMEC\",\n",
    "    \"GSM1551614_HIC065\": \"NHEK\",\n",
    "    \"GSM1551615_HIC066\": \"NHEK\",\n",
    "    \"GSM1551618_HIC069\": \"K562\",\n",
    "    \"GSM1551619_HIC070\": \"K562\",\n",
    "    \"GSM1551620_HIC071\": \"K562\",\n",
    "    \"GSM1551624_HIC075\": \"KBM7\",\n",
    "    \"GSM1551625_HIC076\": \"KBM7\",\n",
    "    \"GSM1551626_HIC077\": \"KBM7\",\n",
    "    \"GSM1551629_HIC080\": \"HUVEC\",\n",
    "    \"GSM1551630_HIC081\": \"HUVEC\",\n",
    "}\n",
    "\n",
    "all_cells_dataset = HICPairsBioReplicatesDataset(\n",
    "        data_path,\n",
    "        [\n",
    "            # GM12878\n",
    "            (\"GSM1551552_HIC003\", \"GSM1551554_HIC005\"), \n",
    "            # IMR90 (CCL-186)\n",
    "            (\"GSM1551599_HIC050\", \"GSM1551600_HIC051\"),\n",
    "            # HMEC (CC-2551)\n",
    "            (\"GSM1551608_HIC059\", \"GSM1551609_HIC060\"),\n",
    "            # NHEK (192627)\n",
    "            (\"GSM1551614_HIC065\", \"GSM1551615_HIC066\"),\n",
    "            # K562 (CCL-243)\n",
    "            (\"GSM1551618_HIC069\", \"GSM1551619_HIC070\"),\n",
    "            # KBM7\n",
    "            (\"GSM1551625_HIC076\", \"GSM1551626_HIC077\"),\n",
    "            # HUVEC\n",
    "            (\"GSM1551629_HIC080\", \"GSM1551630_HIC081\")\n",
    "        ],\n",
    "        [\n",
    "            # GM12878\n",
    "            (\"GSM1551552_HIC003\", \"GSM1551569_HIC020\"),\n",
    "            # IMR90 (CCL-186)\n",
    "            (\"GSM1551599_HIC050\", \"GSM1551604_HIC055\"),\n",
    "            # HMEC (CC-2551)\n",
    "            (\"GSM1551607_HIC058\", \"GSM1551608_HIC059\"),\n",
    "            # K562 (CCL-243)\n",
    "            (\"GSM1551618_HIC069\", \"GSM1551620_HIC071\"),\n",
    "            # KBM7\n",
    "            (\"GSM1551624_HIC075\", \"GSM1551625_HIC076\"),\n",
    "        ],\n",
    "        None,\n",
    "    )\n",
    "gm12878_dataset = HICPairsBioReplicatesDataset(\n",
    "        data_path,\n",
    "        [\n",
    "            (\"GSM1551552_HIC003\", \"GSM1551554_HIC005\"), \n",
    "        ],\n",
    "        [\n",
    "            (\"GSM1551552_HIC003\", \"GSM1551569_HIC020\"),\n",
    "        ],\n",
    "        None,\n",
    "    )\n",
    "imr90_dataset = HICPairsBioReplicatesDataset(\n",
    "    data_path,\n",
    "    [\n",
    "        (\"GSM1551599_HIC050\", \"GSM1551600_HIC051\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"GSM1551599_HIC050\", \"GSM1551604_HIC055\"),\n",
    "    ],\n",
    "    None,\n",
    ")\n",
    "hmec_dataset = HICPairsBioReplicatesDataset(\n",
    "    data_path,\n",
    "    [\n",
    "        (\"GSM1551608_HIC059\", \"GSM1551609_HIC060\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"GSM1551607_HIC058\", \"GSM1551608_HIC059\"),\n",
    "    ],\n",
    "    None,\n",
    ")\n",
    "k562_dataset = HICPairsBioReplicatesDataset(\n",
    "    data_path,\n",
    "    [\n",
    "        (\"GSM1551618_HIC069\", \"GSM1551619_HIC070\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"GSM1551618_HIC069\", \"GSM1551620_HIC071\"),\n",
    "    ],\n",
    "    None,\n",
    ")\n",
    "kbm7_dataset = HICPairsBioReplicatesDataset(\n",
    "    data_path,\n",
    "    [\n",
    "        (\"GSM1551625_HIC076\", \"GSM1551626_HIC077\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"GSM1551624_HIC075\", \"GSM1551625_HIC076\"),\n",
    "    ],\n",
    "    None\n",
    ")\n",
    "\n",
    "datasets_by_cell_type = {\n",
    "    \"gm12878\": gm12878_dataset,\n",
    "    \"imr90\": imr90_dataset,\n",
    "    \"hmec\": hmec_dataset,\n",
    "    \"k562\": k562_dataset,\n",
    "    \"kbm7\": kbm7_dataset\n",
    "}\n",
    "\n",
    "\n",
    "def train_once(model, train_loader, criterion, optimizer):\n",
    "    print(\"Training model...\")\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i,batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input1, input2, label = batch[\"input1\"], batch[\"input2\"], batch[\"label\"]\n",
    "        output = model(input1.to(device), input2.to(device))\n",
    "        loss = criterion(output, label.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        print(f\"Batch: {i + 1}/{len(train_loader)}, Loss: {running_loss / (i + 1)}\", end=\"\\r\")\n",
    "\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "def eval_once(model, test_data, criteria):\n",
    "    print(\"Evaluating model...\")\n",
    "    model.eval()\n",
    "\n",
    "    metrics = {name: 0.0 for name, _ in criteria}\n",
    "    with torch.no_grad():\n",
    "        for i,batch in enumerate(test_data):\n",
    "            input1, input2, label = batch[\"input1\"], batch[\"input2\"], batch[\"label\"]\n",
    "            output = model(input1.to(device), input2.to(device))\n",
    "\n",
    "            for name, criterion in criteria:\n",
    "                metric_value = criterion(output.squeeze(1).cpu(), label.squeeze(1).cpu())\n",
    "                metrics[name] += metric_value\n",
    "            print(f\"Batch: {i + 1}/{len(test_data)}\", end=\"\\r\")\n",
    "\n",
    "    return {name: metric_value / len(test_data) for name, metric_value in metrics.items()}\n",
    "    \n",
    "def train_loop(model, train_loader, eval_loader, test_loader, batch_size, num_epochs, criterion, optimizer, eval_metrics, save_dir):\n",
    "    # Training loop\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_accuracy\": [],\n",
    "    }\n",
    "\n",
    "    json.dump({\"batch_size\": batch_size, \"num_epochs\": num_epochs, \"criterion\": str(criterion), \"optimizer\": str(optimizer), \"model\": str(type(model))}, open(f\"{save_dir}/params.json\", \"w\"), indent=4)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch: {epoch + 1}\")\n",
    "        \n",
    "        history[\"train_loss\"].append(train_once(model, train_loader, criterion, optimizer))\n",
    "        epoch_val_metrics = eval_once(model, eval_loader, eval_metrics)\n",
    "        for name, value in epoch_val_metrics.items():\n",
    "            history[f\"test_{name}\"].append(value)\n",
    "        \n",
    "        checkpoint_path = f\"{save_dir}/epoch_{epoch + 1}.pt\"\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        print(f\"Train loss: {history['train_loss'][-1]:.4f}, Test loss: {epoch_val_metrics['loss']:.4f} Test accuracy: {epoch_val_metrics['accuracy']:.4f}\")\n",
    "    torch.save(model.state_dict(), f\"{save_dir}/final.pt\")\n",
    "    json.dump(history, open(f\"{save_dir}/history.json\", \"w\"), indent=4)\n",
    "\n",
    "    best_checkpoint = save_dir / get_best_checkpoint(history)\n",
    "    model.load_state_dict(torch.load(best_checkpoint))\n",
    "    test_metrics = eval_once(model, test_loader, eval_metrics)\n",
    "    json.dump(test_metrics, open(save_dir / \"test_metrics.json\", \"w\"), indent=4)\n",
    "\n",
    "def get_whole_dataset_split(repro_seed=None):\n",
    "    train_size, val_size = int(0.6 * len(all_cells_dataset)), int(0.2 * len(all_cells_dataset))\n",
    "    test_size = len(all_cells_dataset) - train_size - val_size\n",
    "\n",
    "    generator = torch.Generator().manual_seed(repro_seed) if repro_seed is not None else None\n",
    "    return random_split(all_cells_dataset, [train_size, val_size, test_size], generator=generator)\n",
    "\n",
    "def get_dataset_split_by_cell_type(train_cell_types, test_cell_types, repro_seed=None):\n",
    "    train_dataset = ConcatDataset([datasets_by_cell_type[cell_type] for cell_type in train_cell_types])\n",
    "    test_dataset = ConcatDataset([datasets_by_cell_type[cell_type] for cell_type in test_cell_types])\n",
    "\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "\n",
    "    generator = torch.Generator().manual_seed(repro_seed) if repro_seed is not None else None\n",
    "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size], generator=generator)\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "def get_best_checkpoint(history):\n",
    "    epoch = np.argmax(history[\"test_accuracy\"])\n",
    "    return f\"epoch_{epoch + 1}.pt\"\n",
    "\n",
    "def dump_analytics_to_df(dataset, models, experiment_to_cell_type):\n",
    "    loaded_models = []\n",
    "    for _, model_exp, SiameseNetworkXEncoder in models:\n",
    "        exp = Path(model_exp)\n",
    "        best_checkpoint = get_best_checkpoint(json.load(open(exp / \"history.json\")))\n",
    "        model = SiameseNetworkXEncoder((40, 40)).to(device)\n",
    "        model.load_state_dict(torch.load(exp / best_checkpoint))\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        loaded_models.append(model)\n",
    "\n",
    "    columns = [\"cell_type\", \"chr\", \"low\", \"high\", \"label\"] + [model_name for model_name, _, _ in models]\n",
    "\n",
    "    rows = []\n",
    "    for tuple in tqdm(dataset):\n",
    "        input1, input2, label, extra = tuple[\"input1\"], tuple[\"input2\"], tuple[\"label\"], tuple[\"extra1\"]\n",
    "        row = [experiment_to_cell_type[extra[\"experiment\"]], extra[\"chr\"], extra[\"window\"][0], extra[\"window\"][1], int(label.item())]\n",
    "\n",
    "        input1, input2 = input1.unsqueeze(0).to(device), input2.unsqueeze(0).to(device)\n",
    "        for model in loaded_models:\n",
    "            prediction = int(model(input1, input2) > 0.5)\n",
    "            row.append(prediction)\n",
    "        \n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows, columns=columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental setup 1: Train and evaluate with all the cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoint_dir = Path(\"../checkpoints/\" + exp_name)\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "batch_size = 800\n",
    "num_epochs = 10\n",
    "criterion = torch.nn.BCELoss()\n",
    "eval_metrics = [(\"loss\", lambda x,y: criterion(x,y).item()), (\"accuracy\", lambda x, y: accuracy_score((x > 0.5).int(), y))]\n",
    "\n",
    "\n",
    "for exp_no in range(3):\n",
    "    # Create data loaders\n",
    "    train_data, val_data, test_data = get_whole_dataset_split(repro_seed=exp_no)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    models = []\n",
    "    for name, SiameseNetworkClass in [\n",
    "        (\"resnet\", SiameseNetworkResnetEncoder),\n",
    "        (\"lenet\", SiameseNetworkLeNetEncoder),\n",
    "        (\"linear\", SiameseNetworkLinearEncoder)\n",
    "    ]:\n",
    "        # Create model and optimizer instances\n",
    "        model = SiameseNetworkClass((40, 40)).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "        # Create save directory\n",
    "        save_dir = checkpoint_dir / f\"all_{name}-{exp_no}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "        save_dir.mkdir(parents=True)\n",
    "\n",
    "        # Train model\n",
    "        train_loop(model, train_loader, val_loader, test_loader, batch_size, num_epochs, criterion, optimizer, eval_metrics, save_dir)\n",
    "\n",
    "        models.append((name, model))\n",
    "    \n",
    "      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Train with a subset of the cell types and test with another"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "train_test_cell_types = [\n",
    "    ([\"gm12878\", \"imr90\", \"hmec\", \"k562\"], [\"kbm7\"]),\n",
    "    ([\"gm12878\", \"imr90\", \"hmec\", \"kbm7\"], [\"k562\"]),\n",
    "    ([\"gm12878\", \"imr90\", \"k562\", \"kbm7\"], [\"hmec\"]),\n",
    "    ([\"gm12878\", \"hmec\", \"k562\", \"kbm7\"], [\"imr90\"]),\n",
    "    ([\"imr90\", \"hmec\", \"k562\", \"kbm7\"], [\"gm12878\"]),\n",
    "]\n",
    "\n",
    "checkpoint_dir = \"../checkpoints\"\n",
    "batch_size = 800\n",
    "num_epochs = 30\n",
    "criterion = torch.nn.BCELoss()\n",
    "eval_metrics = [(\"loss\", lambda x,y: criterion(x,y).item()), (\"accuracy\", lambda x, y: accuracy_score((x > 0.5).int(), y))]\n",
    "\n",
    "for exp_no, (train_cell_types, test_cell_types) in enumerate(train_test_cell_types):\n",
    "    train_dataset, val_dataset, test_dataset = get_dataset_split_by_cell_type(train_cell_types, test_cell_types, repro_seed=exp_no)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for name, SiameseNetworkClass in [\n",
    "        (\"resnet\", SiameseNetworkResnetEncoder),\n",
    "        (\"lenet\", SiameseNetworkLeNetEncoder),\n",
    "        (\"linear\", SiameseNetworkLinearEncoder)\n",
    "    ]:\n",
    "        # Create model and optimizer instances\n",
    "        model = SiameseNetworkClass((40, 40)).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "        # Create save directory\n",
    "        save_dir = Path(f\"../checkpoints/celltype_{name}-{'-'.join(train_cell_types)}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\")\n",
    "        save_dir.mkdir(parents=True)\n",
    "\n",
    "        # Train model\n",
    "        train_loop(model, train_loader, val_loader, test_loader, batch_size, num_epochs, criterion, optimizer, eval_metrics, save_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Dumping analytics\n",
    "analytics_dir = Path(\"../analytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_no = 0\n",
    "\n",
    "# All cell types\n",
    "\n",
    "# get data of all cell types, exp0\n",
    "train_data, val_data, test_data = get_whole_dataset_split(exp_no)\n",
    "models = [\n",
    "    (\"resnet\", \"../checkpoints/all_resnet-0_2023-05-06_13-27-41\", SiameseNetworkResnetEncoder),\n",
    "    (\"lenet\", \"../checkpoints/all_lenet-0_2023-05-06_14-54-12\", SiameseNetworkLeNetEncoder),\n",
    "    (\"linear\", \"../checkpoints/all_linear-0_2023-05-06_16-36-28\", SiameseNetworkLinearEncoder),\n",
    "]\n",
    "\n",
    "train_df = dump_analytics_to_df(train_data, models, experiment_to_cell_type)\n",
    "train_df.to_csv(analytics_dir / f\"all{exp_no}_train.csv\", index=False)\n",
    "val_df = dump_analytics_to_df(val_data, models, experiment_to_cell_type)\n",
    "val_df.to_csv(analytics_dir / f\"all{exp_no}_val.csv\", index=False)\n",
    "test_df = dump_analytics_to_df(test_data, models, experiment_to_cell_type)\n",
    "test_df.to_csv(analytics_dir / f\"all{exp_no}_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different cell types\n",
    "\n",
    "experiments = [\n",
    "    ([\"gm12878\", \"imr90\", \"hmec\", \"k562\"], [\"kbm7\"]),\n",
    "    ([\"gm12878\", \"imr90\", \"hmec\", \"kbm7\"], [\"k562\"]),\n",
    "    ([\"gm12878\", \"imr90\", \"k562\", \"kbm7\"], [\"hmec\"]),\n",
    "    ([\"gm12878\", \"hmec\", \"k562\", \"kbm7\"], [\"imr90\"]),\n",
    "    ([\"imr90\", \"hmec\", \"k562\", \"kbm7\"], [\"gm12878\"]),\n",
    "]\n",
    "\n",
    "def find_with_prefix(path, prefix):\n",
    "    return next(p for p in path.iterdir() if p.name.startswith(prefix))\n",
    "\n",
    "exp_no = 4\n",
    "train_cell_types, test_cell_types = experiments[exp_no]\n",
    "exp = \"-\".join(train_cell_types)\n",
    "\n",
    "resnet_exp = find_with_prefix(Path(\"../checkpoints\"), f\"celltype_resnet-{exp}\")\n",
    "lenet_exp = find_with_prefix(Path(\"../checkpoints\"), f\"celltype_lenet-{exp}\")\n",
    "linear_exp = find_with_prefix(Path(\"../checkpoints\"), f\"celltype_linear-{exp}\")\n",
    "\n",
    "train_data, val_data, test_data = get_dataset_split_by_cell_type(train_cell_types, test_cell_types, exp_no)\n",
    "models = [\n",
    "    (\"resnet\", f\"../checkpoints/{resnet_exp}\", SiameseNetworkResnetEncoder),\n",
    "    (\"lenet\", f\"../checkpoints/{lenet_exp}\", SiameseNetworkLeNetEncoder),\n",
    "    (\"linear\", f\"../checkpoints/{linear_exp}\", SiameseNetworkLinearEncoder),\n",
    "]\n",
    "\n",
    "train_df = dump_analytics_to_df(train_data, models, experiment_to_cell_type)\n",
    "train_df.to_csv(analytics_dir / f\"celltype_{exp}_train.csv\", index=False)\n",
    "val_df = dump_analytics_to_df(val_data, models, experiment_to_cell_type)\n",
    "val_df.to_csv(analytics_dir / f\"celltype_{exp}_val.csv\", index=False)\n",
    "test_df = dump_analytics_to_df(test_data, models, experiment_to_cell_type)\n",
    "test_df.to_csv(analytics_dir / f\"celltype_{exp}_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def get_accuracy_histogram(ax, df, chr, cell_type=None, model=\"resnet\", bins=100):\n",
    "    df = df[df[\"chr\"] == chr]\n",
    "    if cell_type is not None:\n",
    "        df = df[df[\"cell_type\"] == cell_type]\n",
    "\n",
    "    counts, bins = np.histogram(df[\"start_pos\"], 100)\n",
    "    corrects, _ = np.histogram(df[df[\"label\"] == df[model]][\"start_pos\"], bins)\n",
    "    acc = corrects / counts\n",
    "    acc = np.nan_to_num(acc, nan=0)\n",
    "    ax.bar(bins[:-1], acc, width=bins[1] - bins[0])\n",
    "\n",
    "def get_counts_histogram(ax, df, chr, cell_type=None, label=None, bins=100):\n",
    "    df = df[df[\"chr\"] == chr]\n",
    "    if cell_type is not None:\n",
    "        df = df[df[\"cell_type\"] == cell_type]\n",
    "    if label is not None:\n",
    "        df = df[df[\"label\"] == label]\n",
    "\n",
    "    counts, bins = np.histogram(df[\"start_pos\"], 100)\n",
    "    ax.bar(bins[:-1], counts, width=bins[1] - bins[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv(\"../analytics/celltype_gm12878-imr90-hmec-k562_test.csv\")\n",
    "df = df.assign(start_pos=lambda x: x.low // 200000)\n",
    "\n",
    "fig, axes = plt.subplots(4,6)\n",
    "fig.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.95, wspace=0.3, hspace=0.4)\n",
    "chrs = [\n",
    "    \"1\",\n",
    "    \"2\",\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"5\",\n",
    "    \"6\",\n",
    "    \"7\",\n",
    "    \"8\",\n",
    "    \"9\",\n",
    "    \"10\",\n",
    "    \"11\",\n",
    "    \"12\",\n",
    "    \"13\",\n",
    "    \"14\",\n",
    "    \"15\",\n",
    "    \"16\",\n",
    "    \"17\",\n",
    "    \"18\",\n",
    "    \"19\",\n",
    "    \"20\",\n",
    "    \"21\",\n",
    "    \"22\",\n",
    "    \"X\",\n",
    "    \"Y\",\n",
    "]\n",
    "chr_length = {\n",
    "    \"1\": 248956422,\n",
    "    \"2\": 242193529,\n",
    "    \"3\": 198295559,\n",
    "    \"4\": 190214555,\n",
    "    \"5\": 181538259,\n",
    "    \"6\": 170805979,\n",
    "    \"7\": 159345973,\n",
    "    \"8\": 145138636,\n",
    "    \"9\": 138394717,\n",
    "    \"10\": 133797422,\n",
    "    \"11\": 135086622,\n",
    "    \"12\": 133275309,\n",
    "    \"13\": 114364328,\n",
    "    \"14\": 107043718,\n",
    "    \"15\": 101991189,\n",
    "    \"16\": 90338345,\n",
    "    \"17\": 83257441,\n",
    "    \"18\": 80373285,\n",
    "    \"19\": 58617616,\n",
    "    \"20\": 64444167,\n",
    "    \"21\": 46709983,\n",
    "    \"22\": 50818468,\n",
    "    \"X\": 156040895,\n",
    "    \"Y\": 57227415,\n",
    "}\n",
    "chr_length = {k: v // 200000 for k, v in chr_length.items()}\n",
    "\n",
    "axes = axes.flatten()\n",
    "for chr, ax in zip(chrs, axes):\n",
    "    get_accuracy_histogram(ax, df, chr, cell_type=None, model=\"linear\")\n",
    "    # get_counts_histogram(ax, df, chr, cell_type=None)\n",
    "    ax.set_xlim(0, chr_length[chr])\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(chr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_accuracy(df, chr=None, model=\"resnet\"):\n",
    "    if chr is not None:\n",
    "        df = df[df[\"chr\"] == chr]\n",
    "    return accuracy_score(df[\"label\"], df[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in Path(\"../analytics/\").iterdir():\n",
    "    print(exp.name)\n",
    "    df = read_csv(exp)\n",
    "    for chr in chrs + [None]:\n",
    "        accs = []\n",
    "        for model in [\"resnet\", \"lenet\", \"linear\"]:\n",
    "            accs.append(get_accuracy(df, chr, model))\n",
    "        print(f\"{chr} & {round(accs[0], 4)} & {round(accs[1], 4)} & {round(accs[2], 4)} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in Path(\"../analytics/\").iterdir():\n",
    "    print(exp.name)\n",
    "    df = read_csv(exp)\n",
    "    accs = []\n",
    "    for model in [\"resnet\", \"lenet\", \"linear\"]:\n",
    "        accs.append(get_accuracy(df, None, model))\n",
    "    print(f\"Overall & {round(accs[0], 4)} & {round(accs[1], 4)} & {round(accs[2], 4)} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_df = read_csv(\"../analytics/all0_train.csv\")\n",
    "all_val_df = read_csv(\"../analytics/all0_val.csv\")\n",
    "all_test_df = read_csv(\"../analytics/all0_test.csv\")\n",
    "\n",
    "for cell_type in [\"GM12878\", \"IMR90\", \"HMEC\", \"K562\", \"KBM7\"]:\n",
    "    total = 0\n",
    "    for df in [all_train_df, all_val_df, all_test_df]:\n",
    "        total += len(df[df[\"cell_type\"] == cell_type])\n",
    "    print(f\"{cell_type} & {total}\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Path(\"C:/Users/alero/Documents/School/Spring23/Bio/Project/code/data/hic_dataset/GSM1551552_HIC003/1/0.199999.jpg\")\n",
    "im2 = Path(\"C:/Users/alero/Documents/School/Spring23/Bio/Project/code/data/hic_dataset/GSM1551552_HIC003/1/200000.399999.jpg\")\n",
    "im3 = Path(\"C:/Users/alero/Documents/School/Spring23/Bio/Project/code/data/hic_dataset/GSM1551552_HIC003/1/400000.599999.jpg\")\n",
    "im4 = Path(\"C:/Users/alero/Documents/School/Spring23/Bio/Project/code/data/hic_dataset/GSM1551552_HIC003/1/600000.799999.jpg\")\n",
    "im5 = Path(\"C:/Users/alero/Documents/School/Spring23/Bio/Project/code/data/hic_dataset/GSM1551552_HIC003/1/800000.999999.jpg\")\n",
    "im6 = Path(\"C:/Users/alero/Documents/School/Spring23/Bio/Project/code/data/hic_dataset/GSM1551552_HIC003/1/1000000.1199999.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the six images\n",
    "image1 = Image.open(im1).convert('L')\n",
    "image2 = Image.open(im2).convert('L')\n",
    "image3 = Image.open(im3).convert('L')\n",
    "image4 = Image.open(im4).convert('L')\n",
    "image5 = Image.open(im5).convert('L')\n",
    "image6 = Image.open(im6).convert('L')\n",
    "\n",
    "# Create a new figure and set the size and margins\n",
    "fig = plt.figure(figsize=(5, 7))\n",
    "fig.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.95, wspace=0.1, hspace=0.2)\n",
    "\n",
    "# Add the six images to the figure as subplots\n",
    "ax1 = fig.add_subplot(3, 2, 1)\n",
    "ax1.imshow(image1, cmap='gray')\n",
    "ax2 = fig.add_subplot(3, 2, 2)\n",
    "ax2.imshow(image2, cmap='gray')\n",
    "ax3 = fig.add_subplot(3, 2, 3)\n",
    "ax3.imshow(image3, cmap='gray')\n",
    "ax4 = fig.add_subplot(3, 2, 4)\n",
    "ax4.imshow(image4, cmap='gray')\n",
    "ax5 = fig.add_subplot(3, 2, 5)\n",
    "ax5.imshow(image5, cmap='gray')\n",
    "ax6 = fig.add_subplot(3, 2, 6)\n",
    "ax6.imshow(image6, cmap='gray')\n",
    "\n",
    "# Remove the axis labels\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "ax3.axis('off')\n",
    "ax4.axis('off')\n",
    "ax5.axis('off')\n",
    "ax6.axis('off')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
