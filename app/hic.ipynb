{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring HIC contact matrices similarity with Neural Networks\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Questions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consequently, we set out to answer the following research questions:\n",
    "\n",
    "1. Can a neural network be trained to predict biological replicates based on Hi-C contact matrices?\n",
    "2. Does the knowledge from certain cell types generalize to other cell types?\n",
    "3. In either case, in which segments of the DNA does it generalize better, if any?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the three models proposed is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "        Based on https://github.com/pytorch/examples/tree/main/siamese_network\n",
    "        Siamese network for image similarity estimation.\n",
    "        The network is composed of two identical networks, one for each input.\n",
    "        The output of each network is concatenated and passed to a linear layer. \n",
    "        The output of the linear layer passed through a sigmoid function.\n",
    "        `\"FaceNet\" <https://arxiv.org/pdf/1503.03832.pdf>`_ is a variant of the Siamese network.\n",
    "        This implementation varies from FaceNet as we use the `ResNet-18` model from\n",
    "        `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_ as our feature extractor.\n",
    "        In addition, we aren't using `TripletLoss`, `BCELoss` can do the trick.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        self.encoder, encoded_features = self.build_encoder(input_size)\n",
    "\n",
    "        # add linear layers to compare between the features of the two images\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(encoded_features * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # initialize the weights\n",
    "        self.encoder.apply(self.init_weights)\n",
    "        self.fc.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "    def build_encoder(self, input_size, **kwargs):\n",
    "       raise NotImplementedError()\n",
    "\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.encoder(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # get two images' features\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "\n",
    "        # concatenate both images' features\n",
    "        output = torch.cat((output1, output2), 1)\n",
    "\n",
    "        # pass the concatenation to the linear layers\n",
    "        output = self.fc(output)\n",
    "\n",
    "        # pass the out of the linear layers to sigmoid layer\n",
    "        output = self.sigmoid(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class SiameseNetworkResnetEncoder(SiameseNetwork):\n",
    "    def __init__(self, input_size):\n",
    "        super(SiameseNetworkResnetEncoder, self).__init__(input_size)\n",
    "\n",
    "\n",
    "    def build_encoder(self, input_size):\n",
    "        # get resnet model\n",
    "        resnet = torchvision.models.resnet18(pretrained=False)\n",
    "\n",
    "        # over-write the first conv layer to be able to read HIC images\n",
    "        # as resnet18 reads (3,x,x) where 3 is RGB channels\n",
    "        # whereas HIC has (1,x,x) where 1 is a gray-scale channel\n",
    "        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        # remove the last layer of resnet18 (linear layer which is before avgpool layer)\n",
    "        resnet = torch.nn.Sequential(*(list(resnet.children())[:-1]))\n",
    "\n",
    "        return resnet, resnet(torch.rand(1, 1, *input_size)).shape[1]\n",
    "\n",
    "class SiameseNetworkLinearEncoder(SiameseNetwork):\n",
    "    def __init__(self, input_size):\n",
    "        super(SiameseNetworkLinearEncoder, self).__init__(input_size)\n",
    "\n",
    "    def build_encoder(self, input_size):\n",
    "        return nn.Linear(input_size[0] * input_size[1], 256), 256\n",
    "     \n",
    "    def forward_once(self, x):\n",
    "        output = self.encoder(x.view(x.size()[0], -1))\n",
    "        return output\n",
    "    \n",
    "class SiameseNetworkLeNetEncoder(SiameseNetwork):\n",
    "    def __init__(self, input_size):\n",
    "        super(SiameseNetworkLeNetEncoder, self).__init__(input_size)\n",
    "\n",
    "    def build_encoder(self, input_size):\n",
    "        encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "\n",
    "        return encoder, torch.prod(torch.tensor(encoder(torch.rand(1, 1, *input_size)).shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below find the implementation of the dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "class HICPairsBioReplicatesDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir: str,\n",
    "        bio_replicates_pairs: List[Tuple[str]],\n",
    "        non_bio_replicates_pairs: List[Tuple[str]],\n",
    "        chromosomes: List[str],\n",
    "    ):\n",
    "        self.root_dir = Path(root_dir)\n",
    "\n",
    "        print(\"Building positive image pairs\")\n",
    "        self.positive_pairs = self.__build_image_pairs(\n",
    "            bio_replicates_pairs, chromosomes\n",
    "        )\n",
    "\n",
    "        print(\"Building negative image pairs\")\n",
    "        self.negative_pairs = self.__build_image_pairs(\n",
    "            non_bio_replicates_pairs, chromosomes\n",
    "        )\n",
    "\n",
    "        self.all_pairs = self.negative_pairs + self.positive_pairs\n",
    "\n",
    "        self.transform = T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __build_image_pairs(self, pairs: List[Tuple[str]], chromosomes: List[str]):\n",
    "        img_pairs = []\n",
    "        for exp1, exp2 in pairs:\n",
    "            print(f\"Building image pairs for {exp1} and {exp2}\")\n",
    "\n",
    "            dir1, dir2 = Path(self.root_dir / exp1), Path(self.root_dir / exp2)\n",
    "            assert dir1.exists() and dir2.exists(), f\"{dir1} or {dir2} does not exist\"\n",
    "\n",
    "            if chromosomes is None:\n",
    "                chromosomes = set(p.name for p in dir1.iterdir()).intersection(\n",
    "                    set(p.name for p in dir2.iterdir())\n",
    "                )\n",
    "\n",
    "            for chr in tqdm(chromosomes):\n",
    "\n",
    "                chr_dir1, chr_dir2 = dir1 / chr, dir2 / chr\n",
    "                assert (\n",
    "                    chr_dir1.exists() and chr_dir2.exists()\n",
    "                ), f\"{chr_dir1} or {chr_dir2} does not exist\"\n",
    "\n",
    "                dir1_imgs, dir2_imgs = set(p.name for p in chr_dir1.iterdir()), set(\n",
    "                    p.name for p in chr_dir2.iterdir()\n",
    "                )\n",
    "\n",
    "                for img_name in dir1_imgs.intersection(dir2_imgs):\n",
    "                    img_pairs.append((chr_dir1 / img_name, chr_dir2 / img_name))\n",
    "\n",
    "        return img_pairs\n",
    "\n",
    "    def __get_extra_info(self, path):\n",
    "        return {\n",
    "            \"experiment\": path.parent.parent.name,\n",
    "            \"window\": tuple(map(int, path.stem.split(\".\"))),\n",
    "            \"chr\": path.parent.name,\n",
    "            \"path\": str(path)\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        src_img1, src_img2 = self.all_pairs[index]\n",
    "        img1, img2 = self.transform(Image.open(src_img1)), self.transform(Image.open(src_img2))\n",
    "        return {\n",
    "            \"input1\": img1,\n",
    "            \"input2\": img2,\n",
    "            \"label\": torch.tensor([0 if index < len(self.negative_pairs) else 1], dtype=torch.float32),\n",
    "            \"extra1\": self.__get_extra_info(src_img1),\n",
    "            \"extra2\": self.__get_extra_info(src_img2),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_pairs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the training procedures and util functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from torch.utils.data import ConcatDataset, random_split\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_path = \"../data/hic_dataset/\"\n",
    "\n",
    "experiment_to_cell_type = {\n",
    "    \"GSM1551552_HIC003\": \"GM12878\",\n",
    "    \"GSM1551554_HIC005\": \"GM12878\",\n",
    "    \"GSM1551569_HIC020\": \"GM12878\",\n",
    "    \"GSM1551599_HIC050\": \"IMR90\",\n",
    "    \"GSM1551600_HIC051\": \"IMR90\",\n",
    "    \"GSM1551604_HIC055\": \"IMR90\",\n",
    "    \"GSM1551607_HIC058\": \"HMEC\",\n",
    "    \"GSM1551608_HIC059\": \"HMEC\",\n",
    "    \"GSM1551609_HIC060\": \"HMEC\",\n",
    "    \"GSM1551614_HIC065\": \"NHEK\",\n",
    "    \"GSM1551615_HIC066\": \"NHEK\",\n",
    "    \"GSM1551618_HIC069\": \"K562\",\n",
    "    \"GSM1551619_HIC070\": \"K562\",\n",
    "    \"GSM1551620_HIC071\": \"K562\",\n",
    "    \"GSM1551624_HIC075\": \"KBM7\",\n",
    "    \"GSM1551625_HIC076\": \"KBM7\",\n",
    "    \"GSM1551626_HIC077\": \"KBM7\",\n",
    "    \"GSM1551629_HIC080\": \"HUVEC\",\n",
    "    \"GSM1551630_HIC081\": \"HUVEC\",\n",
    "}\n",
    "\n",
    "all_cells_dataset = HICPairsBioReplicatesDataset(\n",
    "        data_path,\n",
    "        [\n",
    "            # GM12878\n",
    "            (\"GSM1551552_HIC003\", \"GSM1551554_HIC005\"), \n",
    "            # IMR90 (CCL-186)\n",
    "            (\"GSM1551599_HIC050\", \"GSM1551600_HIC051\"),\n",
    "            # HMEC (CC-2551)\n",
    "            (\"GSM1551608_HIC059\", \"GSM1551609_HIC060\"),\n",
    "            # NHEK (192627)\n",
    "            (\"GSM1551614_HIC065\", \"GSM1551615_HIC066\"),\n",
    "            # K562 (CCL-243)\n",
    "            (\"GSM1551618_HIC069\", \"GSM1551619_HIC070\"),\n",
    "            # KBM7\n",
    "            (\"GSM1551625_HIC076\", \"GSM1551626_HIC077\"),\n",
    "            # HUVEC\n",
    "            (\"GSM1551629_HIC080\", \"GSM1551630_HIC081\")\n",
    "        ],\n",
    "        [\n",
    "            # GM12878\n",
    "            (\"GSM1551552_HIC003\", \"GSM1551569_HIC020\"),\n",
    "            # IMR90 (CCL-186)\n",
    "            (\"GSM1551599_HIC050\", \"GSM1551604_HIC055\"),\n",
    "            # HMEC (CC-2551)\n",
    "            (\"GSM1551607_HIC058\", \"GSM1551608_HIC059\"),\n",
    "            # K562 (CCL-243)\n",
    "            (\"GSM1551618_HIC069\", \"GSM1551620_HIC071\"),\n",
    "            # KBM7\n",
    "            (\"GSM1551624_HIC075\", \"GSM1551625_HIC076\"),\n",
    "        ],\n",
    "        None,\n",
    "    )\n",
    "gm12878_dataset = HICPairsBioReplicatesDataset(\n",
    "        data_path,\n",
    "        [\n",
    "            (\"GSM1551552_HIC003\", \"GSM1551554_HIC005\"), \n",
    "        ],\n",
    "        [\n",
    "            (\"GSM1551552_HIC003\", \"GSM1551569_HIC020\"),\n",
    "        ],\n",
    "        None,\n",
    "    )\n",
    "imr90_dataset = HICPairsBioReplicatesDataset(\n",
    "    data_path,\n",
    "    [\n",
    "        (\"GSM1551599_HIC050\", \"GSM1551600_HIC051\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"GSM1551599_HIC050\", \"GSM1551604_HIC055\"),\n",
    "    ],\n",
    "    None,\n",
    ")\n",
    "hmec_dataset = HICPairsBioReplicatesDataset(\n",
    "    data_path,\n",
    "    [\n",
    "        (\"GSM1551608_HIC059\", \"GSM1551609_HIC060\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"GSM1551607_HIC058\", \"GSM1551608_HIC059\"),\n",
    "    ],\n",
    "    None,\n",
    ")\n",
    "k562_dataset = HICPairsBioReplicatesDataset(\n",
    "    data_path,\n",
    "    [\n",
    "        (\"GSM1551618_HIC069\", \"GSM1551619_HIC070\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"GSM1551618_HIC069\", \"GSM1551620_HIC071\"),\n",
    "    ],\n",
    "    None,\n",
    ")\n",
    "kbm7_dataset = HICPairsBioReplicatesDataset(\n",
    "    data_path,\n",
    "    [\n",
    "        (\"GSM1551625_HIC076\", \"GSM1551626_HIC077\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"GSM1551624_HIC075\", \"GSM1551625_HIC076\"),\n",
    "    ],\n",
    "    None\n",
    ")\n",
    "\n",
    "datasets_by_cell_type = {\n",
    "    \"gm12878\": gm12878_dataset,\n",
    "    \"imr90\": imr90_dataset,\n",
    "    \"hmec\": hmec_dataset,\n",
    "    \"k562\": k562_dataset,\n",
    "    \"kbm7\": kbm7_dataset\n",
    "}\n",
    "\n",
    "\n",
    "def train_once(model, train_loader, criterion, optimizer):\n",
    "    print(\"Training model...\")\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i,batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input1, input2, label = batch[\"input1\"], batch[\"input2\"], batch[\"label\"]\n",
    "        output = model(input1.to(device), input2.to(device))\n",
    "        loss = criterion(output, label.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        print(f\"Batch: {i + 1}/{len(train_loader)}, Loss: {running_loss / (i + 1)}\", end=\"\\r\")\n",
    "\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "def eval_once(model, test_data, criteria):\n",
    "    print(\"Evaluating model...\")\n",
    "    model.eval()\n",
    "\n",
    "    metrics = {name: 0.0 for name, _ in criteria}\n",
    "    with torch.no_grad():\n",
    "        for i,batch in enumerate(test_data):\n",
    "            input1, input2, label = batch[\"input1\"], batch[\"input2\"], batch[\"label\"]\n",
    "            output = model(input1.to(device), input2.to(device))\n",
    "\n",
    "            for name, criterion in criteria:\n",
    "                metric_value = criterion(output.squeeze(1).cpu(), label.squeeze(1).cpu())\n",
    "                metrics[name] += metric_value\n",
    "            print(f\"Batch: {i + 1}/{len(test_data)}\", end=\"\\r\")\n",
    "\n",
    "    return {name: metric_value / len(test_data) for name, metric_value in metrics.items()}\n",
    "    \n",
    "def train_loop(model, train_loader, eval_loader, test_loader, batch_size, num_epochs, criterion, optimizer, eval_metrics, save_dir):\n",
    "    # Training loop\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_accuracy\": [],\n",
    "    }\n",
    "\n",
    "    json.dump({\"batch_size\": batch_size, \"num_epochs\": num_epochs, \"criterion\": str(criterion), \"optimizer\": str(optimizer), \"model\": str(type(model))}, open(f\"{save_dir}/params.json\", \"w\"), indent=4)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch: {epoch + 1}\")\n",
    "        \n",
    "        history[\"train_loss\"].append(train_once(model, train_loader, criterion, optimizer))\n",
    "        epoch_val_metrics = eval_once(model, eval_loader, eval_metrics)\n",
    "        for name, value in epoch_val_metrics.items():\n",
    "            history[f\"test_{name}\"].append(value)\n",
    "        \n",
    "        checkpoint_path = f\"{save_dir}/epoch_{epoch + 1}.pt\"\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        print(f\"Train loss: {history['train_loss'][-1]:.4f}, Test loss: {epoch_val_metrics['loss']:.4f} Test accuracy: {epoch_val_metrics['accuracy']:.4f}\")\n",
    "    torch.save(model.state_dict(), f\"{save_dir}/final.pt\")\n",
    "    json.dump(history, open(f\"{save_dir}/history.json\", \"w\"), indent=4)\n",
    "\n",
    "    best_checkpoint = save_dir / get_best_checkpoint(history)\n",
    "    model.load_state_dict(torch.load(best_checkpoint))\n",
    "    test_metrics = eval_once(model, test_loader, eval_metrics)\n",
    "    json.dump(test_metrics, open(save_dir / \"test_metrics.json\", \"w\"), indent=4)\n",
    "\n",
    "def get_whole_dataset_split(repro_seed=None):\n",
    "    train_size, val_size = int(0.6 * len(all_cells_dataset)), int(0.2 * len(all_cells_dataset))\n",
    "    test_size = len(all_cells_dataset) - train_size - val_size\n",
    "\n",
    "    generator = torch.Generator().manual_seed(repro_seed) if repro_seed is not None else None\n",
    "    return random_split(all_cells_dataset, [train_size, val_size, test_size], generator=generator)\n",
    "\n",
    "def get_dataset_split_by_cell_type(train_cell_types, test_cell_types, repro_seed=None):\n",
    "    train_dataset = ConcatDataset([datasets_by_cell_type[cell_type] for cell_type in train_cell_types])\n",
    "    test_dataset = ConcatDataset([datasets_by_cell_type[cell_type] for cell_type in test_cell_types])\n",
    "\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "\n",
    "    generator = torch.Generator().manual_seed(repro_seed) if repro_seed is not None else None\n",
    "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size], generator=generator)\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "def get_best_checkpoint(history):\n",
    "    epoch = np.argmax(history[\"test_accuracy\"])\n",
    "    return f\"epoch_{epoch + 1}.pt\"\n",
    "\n",
    "\n",
    "def dump_analytics_to_df(dataset, models, experiment_to_cell_type):\n",
    "    loaded_models = []\n",
    "    for _, model_exp, SiameseNetworkXEncoder in models:\n",
    "        exp = Path(model_exp)\n",
    "        best_checkpoint = get_best_checkpoint(json.load(open(exp / \"history.json\")))\n",
    "        model = SiameseNetworkXEncoder((40, 40)).to(device)\n",
    "        model.load_state_dict(torch.load(exp / best_checkpoint))\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        loaded_models.append(model)\n",
    "\n",
    "    columns = [\"cell_type\", \"chr\", \"low\", \"high\", \"label\"] + [model_name for model_name, _, _ in models]\n",
    "\n",
    "    rows = []\n",
    "    for tuple in tqdm(dataset):\n",
    "        input1, input2, label, extra = tuple[\"input1\"], tuple[\"input2\"], tuple[\"label\"], tuple[\"extra1\"]\n",
    "        row = [experiment_to_cell_type[extra[\"experiment\"]], extra[\"chr\"], extra[\"window\"][0], extra[\"window\"][1], int(label.item())]\n",
    "\n",
    "        input1, input2 = input1.unsqueeze(0).to(device), input2.unsqueeze(0).to(device)\n",
    "        for model in loaded_models:\n",
    "            prediction = int(model(input1, input2) > 0.5)\n",
    "            row.append(prediction)\n",
    "        \n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows, columns=columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental setup 1: Train and evaluate with all the cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoint_dir = \"../checkpoints\"\n",
    "batch_size = 800\n",
    "num_epochs = 30\n",
    "criterion = torch.nn.BCELoss()\n",
    "eval_metrics = [(\"loss\", lambda x,y: criterion(x,y).item()), (\"accuracy\", lambda x, y: accuracy_score((x > 0.5).int(), y))]\n",
    "\n",
    "\n",
    "for exp_no in range(3):\n",
    "    # Create data loaders\n",
    "    train_data, val_data, test_data = get_whole_dataset_split(repro_seed=exp_no)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    models = []\n",
    "    for name, SiameseNetworkClass in [\n",
    "        (\"resnet\", SiameseNetworkResnetEncoder),\n",
    "        (\"lenet\", SiameseNetworkLeNetEncoder),\n",
    "        (\"linear\", SiameseNetworkLinearEncoder)\n",
    "    ]:\n",
    "        # Create model and optimizer instances\n",
    "        model = SiameseNetworkClass((40, 40)).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "        # Create save directory\n",
    "        save_dir = Path(f\"../checkpoints/all_{name}-{exp_no}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\")\n",
    "        save_dir.mkdir(parents=True)\n",
    "\n",
    "        # Train model\n",
    "        train_loop(model, train_loader, val_loader, test_loader, batch_size, num_epochs, criterion, optimizer, eval_metrics, save_dir)\n",
    "\n",
    "        models.append((name, model))\n",
    "    \n",
    "      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Train with a subset of the cell types and test with another"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "train_test_cell_types = [\n",
    "    ([\"gm12878\", \"imr90\", \"hmec\", \"k562\"], [\"kbm7\"]),\n",
    "    ([\"gm12878\", \"imr90\", \"hmec\", \"kbm7\"], [\"k562\"]),\n",
    "    ([\"gm12878\", \"imr90\", \"k562\", \"kbm7\"], [\"hmec\"]),\n",
    "    ([\"gm12878\", \"hmec\", \"k562\", \"kbm7\"], [\"imr90\"]),\n",
    "    ([\"imr90\", \"hmec\", \"k562\", \"kbm7\"], [\"gm12878\"]),\n",
    "]\n",
    "\n",
    "checkpoint_dir = \"../checkpoints\"\n",
    "batch_size = 800\n",
    "num_epochs = 30\n",
    "criterion = torch.nn.BCELoss()\n",
    "eval_metrics = [(\"loss\", lambda x,y: criterion(x,y).item()), (\"accuracy\", lambda x, y: accuracy_score((x > 0.5).int(), y))]\n",
    "\n",
    "for exp_no, (train_cell_types, test_cell_types) in enumerate(train_test_cell_types):\n",
    "    train_dataset, val_dataset, test_dataset = get_dataset_split_by_cell_type(train_cell_types, test_cell_types, repro_seed=exp_no)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for name, SiameseNetworkClass in [\n",
    "        (\"resnet\", SiameseNetworkResnetEncoder),\n",
    "        (\"lenet\", SiameseNetworkLeNetEncoder),\n",
    "        (\"linear\", SiameseNetworkLinearEncoder)\n",
    "    ]:\n",
    "        # Create model and optimizer instances\n",
    "        model = SiameseNetworkClass((40, 40)).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "        # Create save directory\n",
    "        save_dir = Path(f\"../checkpoints/celltype_{name}-{'-'.join(train_cell_types)}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\")\n",
    "        save_dir.mkdir(parents=True)\n",
    "\n",
    "        # Train model\n",
    "        train_loop(model, train_loader, val_loader, test_loader, batch_size, num_epochs, criterion, optimizer, eval_metrics, save_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Dumping analytics\n",
    "analytics_dir = Path(\"../analytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alero\\Anaconda3\\envs\\ht\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alero\\Anaconda3\\envs\\ht\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 102997/102997 [28:41<00:00, 59.84it/s]\n",
      "c:\\Users\\alero\\Anaconda3\\envs\\ht\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alero\\Anaconda3\\envs\\ht\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 34332/34332 [09:24<00:00, 60.87it/s]\n",
      "c:\\Users\\alero\\Anaconda3\\envs\\ht\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alero\\Anaconda3\\envs\\ht\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 34334/34334 [09:04<00:00, 63.01it/s]\n"
     ]
    }
   ],
   "source": [
    "exp_no = 0\n",
    "\n",
    "# All cell types\n",
    "\n",
    "# get data of all cell types, exp0\n",
    "train_data, val_data, test_data = get_whole_dataset_split(exp_no)\n",
    "models = [\n",
    "    (\"resnet\", \"../checkpoints/all_resnet-0_2023-05-06_13-27-41\", SiameseNetworkResnetEncoder),\n",
    "    (\"lenet\", \"../checkpoints/all_lenet-0_2023-05-06_14-54-12\", SiameseNetworkLeNetEncoder),\n",
    "    (\"linear\", \"../checkpoints/all_linear-0_2023-05-06_16-36-28\", SiameseNetworkLinearEncoder),\n",
    "]\n",
    "\n",
    "train_df = dump_analytics_to_df(train_data, models, experiment_to_cell_type)\n",
    "train_df.to_csv(analytics_dir / f\"all{exp_no}_train.csv\", index=False)\n",
    "val_df = dump_analytics_to_df(val_data, models, experiment_to_cell_type)\n",
    "val_df.to_csv(analytics_dir / f\"all{exp_no}_val.csv\", index=False)\n",
    "test_df = dump_analytics_to_df(test_data, models, experiment_to_cell_type)\n",
    "test_df.to_csv(analytics_dir / f\"all{exp_no}_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alero\\Anaconda3\\envs\\ht\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alero\\Anaconda3\\envs\\ht\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 91500/91500 [25:55<00:00, 58.82it/s]\n",
      "c:\\Users\\alero\\Anaconda3\\envs\\ht\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alero\\Anaconda3\\envs\\ht\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 22876/22876 [05:57<00:00, 63.97it/s]\n",
      "c:\\Users\\alero\\Anaconda3\\envs\\ht\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alero\\Anaconda3\\envs\\ht\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 28618/28618 [07:44<00:00, 61.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Different cell types\n",
    "\n",
    "experiments = [\n",
    "    ([\"gm12878\", \"imr90\", \"hmec\", \"k562\"], [\"kbm7\"]),\n",
    "    ([\"gm12878\", \"imr90\", \"hmec\", \"kbm7\"], [\"k562\"]),\n",
    "    ([\"gm12878\", \"imr90\", \"k562\", \"kbm7\"], [\"hmec\"]),\n",
    "    ([\"gm12878\", \"hmec\", \"k562\", \"kbm7\"], [\"imr90\"]),\n",
    "    ([\"imr90\", \"hmec\", \"k562\", \"kbm7\"], [\"gm12878\"]),\n",
    "]\n",
    "\n",
    "def find_with_prefix(path, prefix):\n",
    "    return next(p for p in path.iterdir() if p.name.startswith(prefix))\n",
    "\n",
    "exp_no = 4\n",
    "train_cell_types, test_cell_types = experiments[exp_no]\n",
    "exp = \"-\".join(train_cell_types)\n",
    "\n",
    "resnet_exp = find_with_prefix(Path(\"../checkpoints\"), f\"celltype_resnet-{exp}\")\n",
    "lenet_exp = find_with_prefix(Path(\"../checkpoints\"), f\"celltype_lenet-{exp}\")\n",
    "linear_exp = find_with_prefix(Path(\"../checkpoints\"), f\"celltype_linear-{exp}\")\n",
    "\n",
    "train_data, val_data, test_data = get_dataset_split_by_cell_type(train_cell_types, test_cell_types, exp_no)\n",
    "models = [\n",
    "    (\"resnet\", f\"../checkpoints/{resnet_exp}\", SiameseNetworkResnetEncoder),\n",
    "    (\"lenet\", f\"../checkpoints/{lenet_exp}\", SiameseNetworkLeNetEncoder),\n",
    "    (\"linear\", f\"../checkpoints/{linear_exp}\", SiameseNetworkLinearEncoder),\n",
    "]\n",
    "\n",
    "train_df = dump_analytics_to_df(train_data, models, experiment_to_cell_type)\n",
    "train_df.to_csv(analytics_dir / f\"celltype_{exp}_train.csv\", index=False)\n",
    "val_df = dump_analytics_to_df(val_data, models, experiment_to_cell_type)\n",
    "val_df.to_csv(analytics_dir / f\"celltype_{exp}_val.csv\", index=False)\n",
    "test_df = dump_analytics_to_df(test_data, models, experiment_to_cell_type)\n",
    "test_df.to_csv(analytics_dir / f\"celltype_{exp}_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def get_accuracy_histogram(ax, df, chr, cell_type=None, model=\"resnet\", bins=100):\n",
    "    df = df[df[\"chr\"] == chr]\n",
    "    if cell_type is not None:\n",
    "        df = df[df[\"cell_type\"] == cell_type]\n",
    "\n",
    "    counts, bins = np.histogram(df[\"start_pos\"], 100)\n",
    "    corrects, _ = np.histogram(df[df[\"label\"] == df[model]][\"start_pos\"], bins)\n",
    "    acc = corrects / counts\n",
    "    acc = np.nan_to_num(acc, nan=0)\n",
    "    ax.bar(bins[:-1], acc, width=bins[1] - bins[0])\n",
    "\n",
    "def get_counts_histogram(ax, df, chr, cell_type=None, label=None, bins=100):\n",
    "    df = df[df[\"chr\"] == chr]\n",
    "    if cell_type is not None:\n",
    "        df = df[df[\"cell_type\"] == cell_type]\n",
    "    if label is not None:\n",
    "        df = df[df[\"label\"] == label]\n",
    "\n",
    "    counts, bins = np.histogram(df[\"start_pos\"], 100)\n",
    "    ax.bar(bins[:-1], counts, width=bins[1] - bins[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alero\\AppData\\Local\\Temp\\ipykernel_2172\\4227160043.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = corrects / counts\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv(\"../analytics/celltype_gm12878-imr90-hmec-k562_test.csv\")\n",
    "df = df.assign(start_pos=lambda x: x.low // 200000)\n",
    "\n",
    "fig, axes = plt.subplots(4,6)\n",
    "fig.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.95, wspace=0.3, hspace=0.4)\n",
    "chrs = [\n",
    "    \"1\",\n",
    "    \"2\",\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"5\",\n",
    "    \"6\",\n",
    "    \"7\",\n",
    "    \"8\",\n",
    "    \"9\",\n",
    "    \"10\",\n",
    "    \"11\",\n",
    "    \"12\",\n",
    "    \"13\",\n",
    "    \"14\",\n",
    "    \"15\",\n",
    "    \"16\",\n",
    "    \"17\",\n",
    "    \"18\",\n",
    "    \"19\",\n",
    "    \"20\",\n",
    "    \"21\",\n",
    "    \"22\",\n",
    "    \"X\",\n",
    "    \"Y\",\n",
    "]\n",
    "chr_length = {\n",
    "    \"1\": 248956422,\n",
    "    \"2\": 242193529,\n",
    "    \"3\": 198295559,\n",
    "    \"4\": 190214555,\n",
    "    \"5\": 181538259,\n",
    "    \"6\": 170805979,\n",
    "    \"7\": 159345973,\n",
    "    \"8\": 145138636,\n",
    "    \"9\": 138394717,\n",
    "    \"10\": 133797422,\n",
    "    \"11\": 135086622,\n",
    "    \"12\": 133275309,\n",
    "    \"13\": 114364328,\n",
    "    \"14\": 107043718,\n",
    "    \"15\": 101991189,\n",
    "    \"16\": 90338345,\n",
    "    \"17\": 83257441,\n",
    "    \"18\": 80373285,\n",
    "    \"19\": 58617616,\n",
    "    \"20\": 64444167,\n",
    "    \"21\": 46709983,\n",
    "    \"22\": 50818468,\n",
    "    \"X\": 156040895,\n",
    "    \"Y\": 57227415,\n",
    "}\n",
    "chr_length = {k: v // 200000 for k, v in chr_length.items()}\n",
    "\n",
    "axes = axes.flatten()\n",
    "for chr, ax in zip(chrs, axes):\n",
    "    get_accuracy_histogram(ax, df, chr, cell_type=None, model=\"linear\")\n",
    "    # get_counts_histogram(ax, df, chr, cell_type=None)\n",
    "    ax.set_xlim(0, chr_length[chr])\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(chr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_accuracy(df, chr=None, model=\"resnet\"):\n",
    "    if chr is not None:\n",
    "        df = df[df[\"chr\"] == chr]\n",
    "    return accuracy_score(df[\"label\"], df[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all0_test.csv\n",
      "1 & 0.9539 & 0.9476 & 0.9296 \\\\\n",
      "2 & 0.9628 & 0.9531 & 0.934 \\\\\n",
      "3 & 0.9715 & 0.9659 & 0.9493 \\\\\n",
      "4 & 0.9707 & 0.955 & 0.941 \\\\\n",
      "5 & 0.9614 & 0.9544 & 0.937 \\\\\n",
      "6 & 0.9722 & 0.9571 & 0.939 \\\\\n",
      "7 & 0.9552 & 0.9505 & 0.9236 \\\\\n",
      "8 & 0.9624 & 0.9566 & 0.9265 \\\\\n",
      "9 & 0.943 & 0.9282 & 0.9092 \\\\\n",
      "10 & 0.9535 & 0.9467 & 0.9207 \\\\\n",
      "11 & 0.965 & 0.9475 & 0.9313 \\\\\n",
      "12 & 0.9672 & 0.9584 & 0.9508 \\\\\n",
      "13 & 0.9736 & 0.9663 & 0.9363 \\\\\n",
      "14 & 0.9603 & 0.9283 & 0.9302 \\\\\n",
      "15 & 0.9472 & 0.9259 & 0.9188 \\\\\n",
      "16 & 0.9315 & 0.924 & 0.9176 \\\\\n",
      "17 & 0.9542 & 0.9467 & 0.9478 \\\\\n",
      "18 & 0.9632 & 0.9487 & 0.9331 \\\\\n",
      "19 & 0.9404 & 0.9348 & 0.9251 \\\\\n",
      "20 & 0.9712 & 0.9621 & 0.9516 \\\\\n",
      "21 & 0.9356 & 0.9332 & 0.9332 \\\\\n",
      "22 & 0.9291 & 0.922 & 0.9267 \\\\\n",
      "X & 0.9566 & 0.9414 & 0.9311 \\\\\n",
      "Y & 0.7875 & 0.7375 & 0.8125 \\\\\n",
      "None & 0.9592 & 0.9485 & 0.9327 \\\\\n",
      "all0_train.csv\n",
      "1 & 0.9873 & 0.9501 & 0.9559 \\\\\n",
      "2 & 0.9919 & 0.9533 & 0.9537 \\\\\n",
      "3 & 0.9943 & 0.9646 & 0.96 \\\\\n",
      "4 & 0.9945 & 0.9628 & 0.9568 \\\\\n",
      "5 & 0.9902 & 0.9586 & 0.9547 \\\\\n",
      "6 & 0.9918 & 0.9629 & 0.961 \\\\\n",
      "7 & 0.9895 & 0.9529 & 0.9525 \\\\\n",
      "8 & 0.9921 & 0.9539 & 0.9501 \\\\\n",
      "9 & 0.9827 & 0.9287 & 0.9446 \\\\\n",
      "10 & 0.9914 & 0.9476 & 0.9499 \\\\\n",
      "11 & 0.9905 & 0.9503 & 0.9531 \\\\\n",
      "12 & 0.9902 & 0.9586 & 0.9557 \\\\\n",
      "13 & 0.9932 & 0.9631 & 0.9535 \\\\\n",
      "14 & 0.991 & 0.9629 & 0.9548 \\\\\n",
      "15 & 0.987 & 0.9524 & 0.95 \\\\\n",
      "16 & 0.9822 & 0.9309 & 0.9438 \\\\\n",
      "17 & 0.988 & 0.9542 & 0.9609 \\\\\n",
      "18 & 0.9894 & 0.9598 & 0.9579 \\\\\n",
      "19 & 0.9883 & 0.9422 & 0.9589 \\\\\n",
      "20 & 0.9898 & 0.9462 & 0.9518 \\\\\n",
      "21 & 0.9869 & 0.9462 & 0.9454 \\\\\n",
      "22 & 0.9783 & 0.9133 & 0.945 \\\\\n",
      "X & 0.9904 & 0.9442 & 0.9522 \\\\\n",
      "Y & 0.9231 & 0.7724 & 0.8686 \\\\\n",
      "None & 0.9899 & 0.9523 & 0.9537 \\\\\n",
      "all0_val.csv\n",
      "1 & 0.9589 & 0.9511 & 0.9254 \\\\\n",
      "2 & 0.9613 & 0.9556 & 0.9391 \\\\\n",
      "3 & 0.9738 & 0.9643 & 0.9468 \\\\\n",
      "4 & 0.9706 & 0.9573 & 0.9395 \\\\\n",
      "5 & 0.9698 & 0.9527 & 0.939 \\\\\n",
      "6 & 0.9665 & 0.9542 & 0.9389 \\\\\n",
      "7 & 0.9608 & 0.9406 & 0.9297 \\\\\n",
      "8 & 0.9709 & 0.9506 & 0.9314 \\\\\n",
      "9 & 0.9364 & 0.926 & 0.9288 \\\\\n",
      "10 & 0.9583 & 0.945 & 0.9406 \\\\\n",
      "11 & 0.9576 & 0.9515 & 0.9312 \\\\\n",
      "12 & 0.9669 & 0.9593 & 0.9434 \\\\\n",
      "13 & 0.9773 & 0.9573 & 0.9311 \\\\\n",
      "14 & 0.9689 & 0.9557 & 0.9463 \\\\\n",
      "15 & 0.9324 & 0.9284 & 0.9069 \\\\\n",
      "16 & 0.9273 & 0.9212 & 0.9191 \\\\\n",
      "17 & 0.9559 & 0.9322 & 0.9462 \\\\\n",
      "18 & 0.9664 & 0.953 & 0.9418 \\\\\n",
      "19 & 0.9638 & 0.9435 & 0.9391 \\\\\n",
      "20 & 0.9425 & 0.9395 & 0.9277 \\\\\n",
      "21 & 0.9647 & 0.9506 & 0.9341 \\\\\n",
      "22 & 0.9218 & 0.8802 & 0.9169 \\\\\n",
      "X & 0.9526 & 0.9344 & 0.9142 \\\\\n",
      "Y & 0.7568 & 0.7477 & 0.6847 \\\\\n",
      "None & 0.9598 & 0.9471 & 0.933 \\\\\n",
      "celltype_gm12878-hmec-k562-kbm7_test.csv\n",
      "1 & 0.532 & 0.5105 & 0.5201 \\\\\n",
      "2 & 0.5442 & 0.5154 & 0.5209 \\\\\n",
      "3 & 0.5569 & 0.5143 & 0.5215 \\\\\n",
      "4 & 0.5594 & 0.5218 & 0.5356 \\\\\n",
      "5 & 0.569 & 0.5191 & 0.5275 \\\\\n",
      "6 & 0.5628 & 0.5187 & 0.5259 \\\\\n",
      "7 & 0.5678 & 0.5205 & 0.539 \\\\\n",
      "8 & 0.5578 & 0.5195 & 0.5265 \\\\\n",
      "9 & 0.5552 & 0.5209 & 0.5315 \\\\\n",
      "10 & 0.5475 & 0.5173 & 0.5173 \\\\\n",
      "11 & 0.5539 & 0.5129 & 0.519 \\\\\n",
      "12 & 0.5335 & 0.513 & 0.5175 \\\\\n",
      "13 & 0.5655 & 0.5177 & 0.5166 \\\\\n",
      "14 & 0.5566 & 0.509 & 0.5147 \\\\\n",
      "15 & 0.5316 & 0.5146 & 0.5316 \\\\\n",
      "16 & 0.5553 & 0.5201 & 0.5427 \\\\\n",
      "17 & 0.5242 & 0.5217 & 0.5293 \\\\\n",
      "18 & 0.5477 & 0.5119 & 0.5159 \\\\\n",
      "19 & 0.5355 & 0.5124 & 0.5177 \\\\\n",
      "20 & 0.54 & 0.515 & 0.5233 \\\\\n",
      "21 & 0.5475 & 0.514 & 0.5335 \\\\\n",
      "22 & 0.5282 & 0.5311 & 0.5226 \\\\\n",
      "X & 0.6288 & 0.5427 & 0.5861 \\\\\n",
      "Y & 0.54 & 0.6 & 0.6 \\\\\n",
      "None & 0.5549 & 0.5182 & 0.5283 \\\\\n",
      "celltype_gm12878-hmec-k562-kbm7_train.csv\n",
      "1 & 0.9881 & 0.9915 & 0.9766 \\\\\n",
      "2 & 0.9914 & 0.993 & 0.9823 \\\\\n",
      "3 & 0.9938 & 0.9965 & 0.9855 \\\\\n",
      "4 & 0.9916 & 0.9936 & 0.9799 \\\\\n",
      "5 & 0.9933 & 0.9937 & 0.9832 \\\\\n",
      "6 & 0.9926 & 0.9952 & 0.9808 \\\\\n",
      "7 & 0.987 & 0.9924 & 0.9734 \\\\\n",
      "8 & 0.9941 & 0.9937 & 0.9773 \\\\\n",
      "9 & 0.9781 & 0.982 & 0.9556 \\\\\n",
      "10 & 0.9884 & 0.9924 & 0.9712 \\\\\n",
      "11 & 0.9926 & 0.9945 & 0.981 \\\\\n",
      "12 & 0.9955 & 0.9948 & 0.9833 \\\\\n",
      "13 & 0.9933 & 0.9955 & 0.9843 \\\\\n",
      "14 & 0.9915 & 0.994 & 0.9799 \\\\\n",
      "15 & 0.987 & 0.9912 & 0.9713 \\\\\n",
      "16 & 0.9811 & 0.9838 & 0.966 \\\\\n",
      "17 & 0.9885 & 0.9957 & 0.9838 \\\\\n",
      "18 & 0.9933 & 0.9958 & 0.9825 \\\\\n",
      "19 & 0.9842 & 0.9902 & 0.9706 \\\\\n",
      "20 & 0.9948 & 0.9958 & 0.9849 \\\\\n",
      "21 & 0.987 & 0.9879 & 0.9653 \\\\\n",
      "22 & 0.9832 & 0.9876 & 0.9646 \\\\\n",
      "X & 0.9829 & 0.9884 & 0.9704 \\\\\n",
      "Y & 0.893 & 0.8807 & 0.7984 \\\\\n",
      "None & 0.9896 & 0.9922 & 0.977 \\\\\n",
      "celltype_gm12878-hmec-k562-kbm7_val.csv\n",
      "1 & 0.9787 & 0.9803 & 0.9704 \\\\\n",
      "2 & 0.9816 & 0.9842 & 0.971 \\\\\n",
      "3 & 0.9922 & 0.9942 & 0.9799 \\\\\n",
      "4 & 0.9886 & 0.9899 & 0.9702 \\\\\n",
      "5 & 0.9858 & 0.9886 & 0.9744 \\\\\n",
      "6 & 0.9933 & 0.9904 & 0.974 \\\\\n",
      "7 & 0.9793 & 0.9825 & 0.9697 \\\\\n",
      "8 & 0.9871 & 0.9803 & 0.9666 \\\\\n",
      "9 & 0.9663 & 0.9602 & 0.9418 \\\\\n",
      "10 & 0.9688 & 0.9726 & 0.966 \\\\\n",
      "11 & 0.9925 & 0.9906 & 0.9812 \\\\\n",
      "12 & 0.9896 & 0.9915 & 0.9668 \\\\\n",
      "13 & 0.9945 & 0.9918 & 0.9782 \\\\\n",
      "14 & 0.9914 & 0.9857 & 0.9799 \\\\\n",
      "15 & 0.9626 & 0.9701 & 0.9462 \\\\\n",
      "16 & 0.957 & 0.9693 & 0.9555 \\\\\n",
      "17 & 0.9818 & 0.9802 & 0.9785 \\\\\n",
      "18 & 0.9837 & 0.9918 & 0.9772 \\\\\n",
      "19 & 0.9737 & 0.9737 & 0.9618 \\\\\n",
      "20 & 0.9875 & 0.9916 & 0.9833 \\\\\n",
      "21 & 0.9818 & 0.9891 & 0.9455 \\\\\n",
      "22 & 0.951 & 0.9266 & 0.9161 \\\\\n",
      "X & 0.9672 & 0.9731 & 0.9579 \\\\\n",
      "Y & 0.7561 & 0.7683 & 0.7683 \\\\\n",
      "None & 0.9808 & 0.9819 & 0.9677 \\\\\n",
      "celltype_gm12878-imr90-hmec-k562_test.csv\n",
      "1 & 0.6089 & 0.505 & 0.5647 \\\\\n",
      "2 & 0.5804 & 0.5048 & 0.557 \\\\\n",
      "3 & 0.5922 & 0.5046 & 0.5379 \\\\\n",
      "4 & 0.5515 & 0.5064 & 0.5552 \\\\\n",
      "5 & 0.5716 & 0.5096 & 0.5558 \\\\\n",
      "6 & 0.59 & 0.5072 & 0.553 \\\\\n",
      "7 & 0.5845 & 0.5096 & 0.5519 \\\\\n",
      "8 & 0.7618 & 0.5077 & 0.523 \\\\\n",
      "9 & 0.5751 & 0.5037 & 0.5496 \\\\\n",
      "10 & 0.6075 & 0.5072 & 0.5487 \\\\\n",
      "11 & 0.6017 & 0.5083 & 0.5463 \\\\\n",
      "12 & 0.5907 & 0.5053 & 0.5602 \\\\\n",
      "13 & 0.5551 & 0.5052 & 0.5468 \\\\\n",
      "14 & 0.5814 & 0.5023 & 0.5486 \\\\\n",
      "15 & 0.7141 & 0.5049 & 0.5523 \\\\\n",
      "16 & 0.6508 & 0.5075 & 0.5553 \\\\\n",
      "17 & 0.6556 & 0.5102 & 0.5829 \\\\\n",
      "18 & 0.5822 & 0.508 & 0.5491 \\\\\n",
      "19 & 0.6365 & 0.5035 & 0.5691 \\\\\n",
      "20 & 0.63 & 0.505 & 0.5483 \\\\\n",
      "21 & 0.5782 & 0.5 & 0.5894 \\\\\n",
      "22 & 0.6667 & 0.5056 & 0.5819 \\\\\n",
      "X & 0.5841 & 0.5118 & 0.5427 \\\\\n",
      "Y & 0.554 & 0.5211 & 0.5446 \\\\\n",
      "None & 0.6036 & 0.5067 & 0.5525 \\\\\n",
      "celltype_gm12878-imr90-hmec-k562_train.csv\n",
      "1 & 0.973 & 0.9526 & 0.9491 \\\\\n",
      "2 & 0.9767 & 0.9553 & 0.9506 \\\\\n",
      "3 & 0.9788 & 0.9683 & 0.9548 \\\\\n",
      "4 & 0.9788 & 0.9629 & 0.9498 \\\\\n",
      "5 & 0.9771 & 0.9576 & 0.9516 \\\\\n",
      "6 & 0.9801 & 0.9592 & 0.9559 \\\\\n",
      "7 & 0.9767 & 0.9548 & 0.9518 \\\\\n",
      "8 & 0.9783 & 0.952 & 0.9427 \\\\\n",
      "9 & 0.9605 & 0.9353 & 0.9434 \\\\\n",
      "10 & 0.973 & 0.9477 & 0.9453 \\\\\n",
      "11 & 0.9771 & 0.9493 & 0.9512 \\\\\n",
      "12 & 0.9796 & 0.9574 & 0.9481 \\\\\n",
      "13 & 0.9733 & 0.961 & 0.9457 \\\\\n",
      "14 & 0.9764 & 0.9578 & 0.9465 \\\\\n",
      "15 & 0.9662 & 0.9451 & 0.949 \\\\\n",
      "16 & 0.9687 & 0.9334 & 0.9342 \\\\\n",
      "17 & 0.9777 & 0.9487 & 0.9591 \\\\\n",
      "18 & 0.9727 & 0.9512 & 0.9463 \\\\\n",
      "19 & 0.9721 & 0.9375 & 0.9492 \\\\\n",
      "20 & 0.9723 & 0.9503 & 0.9535 \\\\\n",
      "21 & 0.9729 & 0.9379 & 0.9467 \\\\\n",
      "22 & 0.9573 & 0.9181 & 0.9501 \\\\\n",
      "X & 0.9841 & 0.9439 & 0.947 \\\\\n",
      "Y & 0.837 & 0.6444 & 0.7481 \\\\\n",
      "None & 0.9753 & 0.9521 & 0.9489 \\\\\n",
      "celltype_gm12878-imr90-hmec-k562_val.csv\n",
      "1 & 0.9235 & 0.9377 & 0.8951 \\\\\n",
      "2 & 0.945 & 0.9522 & 0.9218 \\\\\n",
      "3 & 0.9432 & 0.9571 & 0.9344 \\\\\n",
      "4 & 0.9508 & 0.9581 & 0.9215 \\\\\n",
      "5 & 0.952 & 0.9486 & 0.9189 \\\\\n",
      "6 & 0.9456 & 0.9433 & 0.9218 \\\\\n",
      "7 & 0.934 & 0.9324 & 0.8998 \\\\\n",
      "8 & 0.9417 & 0.9454 & 0.908 \\\\\n",
      "9 & 0.9138 & 0.919 & 0.8896 \\\\\n",
      "10 & 0.9349 & 0.9321 & 0.9005 \\\\\n",
      "11 & 0.9316 & 0.9258 & 0.9131 \\\\\n",
      "12 & 0.9468 & 0.9505 & 0.9266 \\\\\n",
      "13 & 0.9508 & 0.9625 & 0.9276 \\\\\n",
      "14 & 0.9381 & 0.941 & 0.8978 \\\\\n",
      "15 & 0.9174 & 0.913 & 0.8982 \\\\\n",
      "16 & 0.9098 & 0.9066 & 0.8908 \\\\\n",
      "17 & 0.9258 & 0.9387 & 0.9129 \\\\\n",
      "18 & 0.9346 & 0.9664 & 0.9211 \\\\\n",
      "19 & 0.9221 & 0.9199 & 0.9156 \\\\\n",
      "20 & 0.9446 & 0.9405 & 0.922 \\\\\n",
      "21 & 0.9123 & 0.9193 & 0.9158 \\\\\n",
      "22 & 0.8771 & 0.884 & 0.8942 \\\\\n",
      "X & 0.9334 & 0.9174 & 0.9064 \\\\\n",
      "Y & 0.5185 & 0.5185 & 0.2963 \\\\\n",
      "None & 0.9355 & 0.9391 & 0.9115 \\\\\n",
      "celltype_gm12878-imr90-hmec-kbm7_test.csv\n",
      "1 & 0.6184 & 0.5033 & 0.5173 \\\\\n",
      "2 & 0.7428 & 0.5044 & 0.5299 \\\\\n",
      "3 & 0.752 & 0.5128 & 0.5312 \\\\\n",
      "4 & 0.7707 & 0.5074 & 0.5372 \\\\\n",
      "5 & 0.722 & 0.5042 & 0.5295 \\\\\n",
      "6 & 0.6258 & 0.5009 & 0.5235 \\\\\n",
      "7 & 0.6251 & 0.4997 & 0.5234 \\\\\n",
      "8 & 0.7611 & 0.5035 & 0.5299 \\\\\n",
      "9 & 0.7884 & 0.5194 & 0.5291 \\\\\n",
      "10 & 0.7494 & 0.5147 & 0.5245 \\\\\n",
      "11 & 0.7549 & 0.5083 & 0.5364 \\\\\n",
      "12 & 0.766 & 0.5099 & 0.532 \\\\\n",
      "13 & 0.8243 & 0.526 & 0.5301 \\\\\n",
      "14 & 0.8835 & 0.5204 & 0.5271 \\\\\n",
      "15 & 0.7418 & 0.5201 & 0.5201 \\\\\n",
      "16 & 0.6947 & 0.5101 & 0.5101 \\\\\n",
      "17 & 0.7806 & 0.5089 & 0.514 \\\\\n",
      "18 & 0.7427 & 0.5106 & 0.5305 \\\\\n",
      "19 & 0.6933 & 0.5018 & 0.516 \\\\\n",
      "20 & 0.8283 & 0.51 & 0.5233 \\\\\n",
      "21 & 0.6145 & 0.5056 & 0.5307 \\\\\n",
      "22 & 0.8729 & 0.5085 & 0.5113 \\\\\n",
      "X & 0.8594 & 0.542 & 0.5539 \\\\\n",
      "Y & 0.5 & 0.3438 & 0.5 \\\\\n",
      "None & 0.7389 & 0.5102 & 0.5281 \\\\\n",
      "celltype_gm12878-imr90-hmec-kbm7_train.csv\n",
      "1 & 0.9542 & 0.9505 & 0.9463 \\\\\n",
      "2 & 0.9556 & 0.9551 & 0.9427 \\\\\n",
      "3 & 0.9635 & 0.9655 & 0.9525 \\\\\n",
      "4 & 0.9601 & 0.9622 & 0.9469 \\\\\n",
      "5 & 0.9517 & 0.9575 & 0.9449 \\\\\n",
      "6 & 0.9542 & 0.9628 & 0.9494 \\\\\n",
      "7 & 0.9524 & 0.9536 & 0.9459 \\\\\n",
      "8 & 0.9537 & 0.9531 & 0.9443 \\\\\n",
      "9 & 0.9441 & 0.9326 & 0.9358 \\\\\n",
      "10 & 0.9473 & 0.9468 & 0.9398 \\\\\n",
      "11 & 0.9574 & 0.9455 & 0.9448 \\\\\n",
      "12 & 0.9574 & 0.954 & 0.9444 \\\\\n",
      "13 & 0.9645 & 0.9681 & 0.9419 \\\\\n",
      "14 & 0.9601 & 0.9541 & 0.9445 \\\\\n",
      "15 & 0.9515 & 0.9454 & 0.9412 \\\\\n",
      "16 & 0.9354 & 0.9283 & 0.933 \\\\\n",
      "17 & 0.9532 & 0.95 & 0.9548 \\\\\n",
      "18 & 0.959 & 0.9586 & 0.9478 \\\\\n",
      "19 & 0.9388 & 0.9349 & 0.9416 \\\\\n",
      "20 & 0.9486 & 0.9491 & 0.9496 \\\\\n",
      "21 & 0.9539 & 0.9321 & 0.946 \\\\\n",
      "22 & 0.9399 & 0.9276 & 0.9443 \\\\\n",
      "X & 0.9437 & 0.9421 & 0.9407 \\\\\n",
      "Y & 0.8456 & 0.7825 & 0.8772 \\\\\n",
      "None & 0.9531 & 0.9514 & 0.9445 \\\\\n",
      "celltype_gm12878-imr90-hmec-kbm7_val.csv\n",
      "1 & 0.9356 & 0.9515 & 0.9251 \\\\\n",
      "2 & 0.9289 & 0.9507 & 0.9263 \\\\\n",
      "3 & 0.9572 & 0.9672 & 0.9411 \\\\\n",
      "4 & 0.9472 & 0.9593 & 0.9275 \\\\\n",
      "5 & 0.9442 & 0.9428 & 0.928 \\\\\n",
      "6 & 0.9531 & 0.9516 & 0.9271 \\\\\n",
      "7 & 0.9336 & 0.9294 & 0.9066 \\\\\n",
      "8 & 0.9187 & 0.9269 & 0.9114 \\\\\n",
      "9 & 0.902 & 0.903 & 0.8931 \\\\\n",
      "10 & 0.9273 & 0.9486 & 0.9137 \\\\\n",
      "11 & 0.941 & 0.9429 & 0.9279 \\\\\n",
      "12 & 0.9496 & 0.957 & 0.9304 \\\\\n",
      "13 & 0.9489 & 0.9552 & 0.9228 \\\\\n",
      "14 & 0.9377 & 0.9518 & 0.9136 \\\\\n",
      "15 & 0.9281 & 0.9147 & 0.9147 \\\\\n",
      "16 & 0.9253 & 0.9091 & 0.9058 \\\\\n",
      "17 & 0.9347 & 0.9407 & 0.9347 \\\\\n",
      "18 & 0.9383 & 0.9433 & 0.925 \\\\\n",
      "19 & 0.9198 & 0.9367 & 0.9135 \\\\\n",
      "20 & 0.9341 & 0.9451 & 0.9275 \\\\\n",
      "21 & 0.9143 & 0.9429 & 0.8893 \\\\\n",
      "22 & 0.912 & 0.9261 & 0.8944 \\\\\n",
      "X & 0.9278 & 0.936 & 0.9113 \\\\\n",
      "Y & 0.6897 & 0.6379 & 0.6724 \\\\\n",
      "None & 0.9352 & 0.9426 & 0.9203 \\\\\n",
      "celltype_gm12878-imr90-k562-kbm7_test.csv\n",
      "1 & 0.4746 & 0.7033 & 0.674 \\\\\n",
      "2 & 0.4816 & 0.7122 & 0.6779 \\\\\n",
      "3 & 0.4939 & 0.7382 & 0.6972 \\\\\n",
      "4 & 0.5345 & 0.7256 & 0.6805 \\\\\n",
      "5 & 0.4848 & 0.7247 & 0.674 \\\\\n",
      "6 & 0.5089 & 0.7339 & 0.6679 \\\\\n",
      "7 & 0.4593 & 0.6944 & 0.672 \\\\\n",
      "8 & 0.4679 & 0.7036 & 0.6674 \\\\\n",
      "9 & 0.4748 & 0.7008 & 0.6664 \\\\\n",
      "10 & 0.4466 & 0.6995 & 0.651 \\\\\n",
      "11 & 0.4467 & 0.7009 & 0.6796 \\\\\n",
      "12 & 0.4627 & 0.7279 & 0.6822 \\\\\n",
      "13 & 0.4875 & 0.7204 & 0.6497 \\\\\n",
      "14 & 0.4344 & 0.6957 & 0.6572 \\\\\n",
      "15 & 0.4518 & 0.6825 & 0.6654 \\\\\n",
      "16 & 0.3819 & 0.6407 & 0.6658 \\\\\n",
      "17 & 0.3495 & 0.6173 & 0.7143 \\\\\n",
      "18 & 0.4735 & 0.7255 & 0.6844 \\\\\n",
      "19 & 0.2966 & 0.5702 & 0.6696 \\\\\n",
      "20 & 0.35 & 0.66 & 0.69 \\\\\n",
      "21 & 0.4479 & 0.6986 & 0.6535 \\\\\n",
      "22 & 0.3249 & 0.5621 & 0.6102 \\\\\n",
      "X & 0.4277 & 0.7122 & 0.6754 \\\\\n",
      "Y & 0.44 & 0.52 & 0.6 \\\\\n",
      "None & 0.4604 & 0.7025 & 0.6736 \\\\\n",
      "celltype_gm12878-imr90-k562-kbm7_train.csv\n",
      "1 & 0.9694 & 0.9588 & 0.9468 \\\\\n",
      "2 & 0.9705 & 0.964 & 0.9508 \\\\\n",
      "3 & 0.9791 & 0.9735 & 0.9553 \\\\\n",
      "4 & 0.9796 & 0.9666 & 0.9573 \\\\\n",
      "5 & 0.9761 & 0.9614 & 0.9529 \\\\\n",
      "6 & 0.9786 & 0.9688 & 0.953 \\\\\n",
      "7 & 0.965 & 0.9578 & 0.9504 \\\\\n",
      "8 & 0.9745 & 0.9601 & 0.95 \\\\\n",
      "9 & 0.9469 & 0.9388 & 0.9443 \\\\\n",
      "10 & 0.9679 & 0.9584 & 0.9492 \\\\\n",
      "11 & 0.9713 & 0.9582 & 0.9503 \\\\\n",
      "12 & 0.9741 & 0.9649 & 0.9504 \\\\\n",
      "13 & 0.9797 & 0.9709 & 0.9529 \\\\\n",
      "14 & 0.9757 & 0.9694 & 0.9489 \\\\\n",
      "15 & 0.9626 & 0.9527 & 0.9524 \\\\\n",
      "16 & 0.9538 & 0.9407 & 0.9458 \\\\\n",
      "17 & 0.9706 & 0.956 & 0.9524 \\\\\n",
      "18 & 0.9751 & 0.968 & 0.9455 \\\\\n",
      "19 & 0.967 & 0.9592 & 0.9503 \\\\\n",
      "20 & 0.9684 & 0.9596 & 0.9519 \\\\\n",
      "21 & 0.9672 & 0.9534 & 0.9569 \\\\\n",
      "22 & 0.9423 & 0.9216 & 0.945 \\\\\n",
      "X & 0.9673 & 0.9513 & 0.9549 \\\\\n",
      "Y & 0.8073 & 0.8073 & 0.9273 \\\\\n",
      "None & 0.9701 & 0.9597 & 0.951 \\\\\n",
      "celltype_gm12878-imr90-k562-kbm7_val.csv\n",
      "1 & 0.9441 & 0.9331 & 0.9282 \\\\\n",
      "2 & 0.948 & 0.9502 & 0.9303 \\\\\n",
      "3 & 0.9678 & 0.9634 & 0.9439 \\\\\n",
      "4 & 0.9617 & 0.9571 & 0.9353 \\\\\n",
      "5 & 0.9457 & 0.95 & 0.9267 \\\\\n",
      "6 & 0.9573 & 0.9581 & 0.9364 \\\\\n",
      "7 & 0.9488 & 0.9455 & 0.9333 \\\\\n",
      "8 & 0.9527 & 0.9432 & 0.9251 \\\\\n",
      "9 & 0.902 & 0.903 & 0.8947 \\\\\n",
      "10 & 0.9356 & 0.9328 & 0.9309 \\\\\n",
      "11 & 0.9484 & 0.9456 & 0.9281 \\\\\n",
      "12 & 0.9642 & 0.9526 & 0.9381 \\\\\n",
      "13 & 0.971 & 0.9596 & 0.9141 \\\\\n",
      "14 & 0.9527 & 0.9512 & 0.9254 \\\\\n",
      "15 & 0.9128 & 0.9221 & 0.9034 \\\\\n",
      "16 & 0.8991 & 0.9006 & 0.8823 \\\\\n",
      "17 & 0.9482 & 0.9498 & 0.9376 \\\\\n",
      "18 & 0.946 & 0.9476 & 0.9362 \\\\\n",
      "19 & 0.9379 & 0.9358 & 0.9336 \\\\\n",
      "20 & 0.9443 & 0.9486 & 0.9379 \\\\\n",
      "21 & 0.9597 & 0.9414 & 0.9341 \\\\\n",
      "22 & 0.9251 & 0.899 & 0.9088 \\\\\n",
      "X & 0.9398 & 0.9278 & 0.92 \\\\\n",
      "Y & 0.7067 & 0.72 & 0.64 \\\\\n",
      "None & 0.9457 & 0.9422 & 0.9262 \\\\\n",
      "celltype_imr90-hmec-k562-kbm7_test.csv\n",
      "1 & 0.6505 & 0.6255 & 0.6885 \\\\\n",
      "2 & 0.6841 & 0.6615 & 0.6878 \\\\\n",
      "3 & 0.686 & 0.6614 & 0.7008 \\\\\n",
      "4 & 0.7325 & 0.7123 & 0.7081 \\\\\n",
      "5 & 0.6818 & 0.6661 & 0.6947 \\\\\n",
      "6 & 0.6819 & 0.654 & 0.6974 \\\\\n",
      "7 & 0.6771 & 0.6758 & 0.6912 \\\\\n",
      "8 & 0.6825 & 0.6581 & 0.6838 \\\\\n",
      "9 & 0.6492 & 0.6304 & 0.6877 \\\\\n",
      "10 & 0.6471 & 0.6161 & 0.7021 \\\\\n",
      "11 & 0.6495 & 0.6358 & 0.7026 \\\\\n",
      "12 & 0.6768 & 0.6463 & 0.7218 \\\\\n",
      "13 & 0.7225 & 0.6902 & 0.7183 \\\\\n",
      "14 & 0.6719 & 0.6448 & 0.698 \\\\\n",
      "15 & 0.629 & 0.618 & 0.6934 \\\\\n",
      "16 & 0.6181 & 0.6005 & 0.7035 \\\\\n",
      "17 & 0.6314 & 0.611 & 0.7283 \\\\\n",
      "18 & 0.6897 & 0.6737 & 0.7082 \\\\\n",
      "19 & 0.656 & 0.6259 & 0.7092 \\\\\n",
      "20 & 0.605 & 0.6083 & 0.7017 \\\\\n",
      "21 & 0.6955 & 0.6704 & 0.7291 \\\\\n",
      "22 & 0.6158 & 0.5734 & 0.6638 \\\\\n",
      "X & 0.6544 & 0.6564 & 0.6478 \\\\\n",
      "Y & 0.4727 & 0.5636 & 0.5091 \\\\\n",
      "None & 0.6701 & 0.6503 & 0.696 \\\\\n",
      "celltype_imr90-hmec-k562-kbm7_train.csv\n",
      "1 & 0.9734 & 0.9642 & 0.9623 \\\\\n",
      "2 & 0.9777 & 0.9636 & 0.9602 \\\\\n",
      "3 & 0.9821 & 0.9743 & 0.9664 \\\\\n",
      "4 & 0.9774 & 0.9676 & 0.9587 \\\\\n",
      "5 & 0.9785 & 0.9682 & 0.961 \\\\\n",
      "6 & 0.9776 & 0.9672 & 0.9613 \\\\\n",
      "7 & 0.9698 & 0.9602 & 0.9554 \\\\\n",
      "8 & 0.9743 & 0.9638 & 0.9588 \\\\\n",
      "9 & 0.9575 & 0.9391 & 0.953 \\\\\n",
      "10 & 0.9689 & 0.957 & 0.96 \\\\\n",
      "11 & 0.975 & 0.9647 & 0.963 \\\\\n",
      "12 & 0.975 & 0.9654 & 0.9576 \\\\\n",
      "13 & 0.9781 & 0.9691 & 0.9529 \\\\\n",
      "14 & 0.9786 & 0.9704 & 0.9661 \\\\\n",
      "15 & 0.9645 & 0.9513 & 0.969 \\\\\n",
      "16 & 0.9578 & 0.9465 & 0.9578 \\\\\n",
      "17 & 0.9696 & 0.9647 & 0.9611 \\\\\n",
      "18 & 0.9755 & 0.9721 & 0.9628 \\\\\n",
      "19 & 0.9604 & 0.9581 & 0.962 \\\\\n",
      "20 & 0.9764 & 0.9664 & 0.9643 \\\\\n",
      "21 & 0.9649 & 0.9543 & 0.9525 \\\\\n",
      "22 & 0.949 & 0.9455 & 0.9569 \\\\\n",
      "X & 0.9675 & 0.9565 & 0.9575 \\\\\n",
      "Y & 0.832 & 0.8281 & 0.8945 \\\\\n",
      "None & 0.9725 & 0.9624 & 0.96 \\\\\n",
      "celltype_imr90-hmec-k562-kbm7_val.csv\n",
      "1 & 0.9616 & 0.9524 & 0.9312 \\\\\n",
      "2 & 0.966 & 0.9545 & 0.9415 \\\\\n",
      "3 & 0.9722 & 0.9672 & 0.9536 \\\\\n",
      "4 & 0.9685 & 0.9679 & 0.9358 \\\\\n",
      "5 & 0.9585 & 0.9578 & 0.9336 \\\\\n",
      "6 & 0.9683 & 0.9607 & 0.9426 \\\\\n",
      "7 & 0.9586 & 0.9514 & 0.9307 \\\\\n",
      "8 & 0.9566 & 0.9583 & 0.9314 \\\\\n",
      "9 & 0.9354 & 0.9231 & 0.919 \\\\\n",
      "10 & 0.9559 & 0.9529 & 0.9304 \\\\\n",
      "11 & 0.9638 & 0.9549 & 0.9383 \\\\\n",
      "12 & 0.9532 & 0.9522 & 0.9233 \\\\\n",
      "13 & 0.9799 & 0.9638 & 0.9437 \\\\\n",
      "14 & 0.9591 & 0.9619 & 0.9278 \\\\\n",
      "15 & 0.9545 & 0.9592 & 0.9309 \\\\\n",
      "16 & 0.9454 & 0.9586 & 0.9222 \\\\\n",
      "17 & 0.9547 & 0.9609 & 0.9344 \\\\\n",
      "18 & 0.9738 & 0.9538 & 0.9431 \\\\\n",
      "19 & 0.9408 & 0.9362 & 0.9362 \\\\\n",
      "20 & 0.9554 & 0.9533 & 0.9554 \\\\\n",
      "21 & 0.9313 & 0.9381 & 0.9107 \\\\\n",
      "22 & 0.9424 & 0.9245 & 0.9173 \\\\\n",
      "X & 0.9538 & 0.9521 & 0.9272 \\\\\n",
      "Y & 0.7812 & 0.7656 & 0.7344 \\\\\n",
      "None & 0.9593 & 0.9546 & 0.9341 \\\\\n"
     ]
    }
   ],
   "source": [
    "for exp in Path(\"../analytics/\").iterdir():\n",
    "    print(exp.name)\n",
    "    df = read_csv(exp)\n",
    "    for chr in chrs + [None]:\n",
    "        accs = []\n",
    "        for model in [\"resnet\", \"lenet\", \"linear\"]:\n",
    "            accs.append(get_accuracy(df, chr, model))\n",
    "        print(f\"{chr} & {round(accs[0], 4)} & {round(accs[1], 4)} & {round(accs[2], 4)} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all0_test.csv\n",
      "Overall & 0.9592 & 0.9485 & 0.9327 \\\\\n",
      "all0_train.csv\n",
      "Overall & 0.9899 & 0.9523 & 0.9537 \\\\\n",
      "all0_val.csv\n",
      "Overall & 0.9598 & 0.9471 & 0.933 \\\\\n",
      "celltype_gm12878-hmec-k562-kbm7_test.csv\n",
      "Overall & 0.5549 & 0.5182 & 0.5283 \\\\\n",
      "celltype_gm12878-hmec-k562-kbm7_train.csv\n",
      "Overall & 0.9896 & 0.9922 & 0.977 \\\\\n",
      "celltype_gm12878-hmec-k562-kbm7_val.csv\n",
      "Overall & 0.9808 & 0.9819 & 0.9677 \\\\\n",
      "celltype_gm12878-imr90-hmec-k562_test.csv\n",
      "Overall & 0.6036 & 0.5067 & 0.5525 \\\\\n",
      "celltype_gm12878-imr90-hmec-k562_train.csv\n",
      "Overall & 0.9753 & 0.9521 & 0.9489 \\\\\n",
      "celltype_gm12878-imr90-hmec-k562_val.csv\n",
      "Overall & 0.9355 & 0.9391 & 0.9115 \\\\\n",
      "celltype_gm12878-imr90-hmec-kbm7_test.csv\n",
      "Overall & 0.7389 & 0.5102 & 0.5281 \\\\\n",
      "celltype_gm12878-imr90-hmec-kbm7_train.csv\n",
      "Overall & 0.9531 & 0.9514 & 0.9445 \\\\\n",
      "celltype_gm12878-imr90-hmec-kbm7_val.csv\n",
      "Overall & 0.9352 & 0.9426 & 0.9203 \\\\\n",
      "celltype_gm12878-imr90-k562-kbm7_test.csv\n",
      "Overall & 0.4604 & 0.7025 & 0.6736 \\\\\n",
      "celltype_gm12878-imr90-k562-kbm7_train.csv\n",
      "Overall & 0.9701 & 0.9597 & 0.951 \\\\\n",
      "celltype_gm12878-imr90-k562-kbm7_val.csv\n",
      "Overall & 0.9457 & 0.9422 & 0.9262 \\\\\n",
      "celltype_imr90-hmec-k562-kbm7_test.csv\n",
      "Overall & 0.6701 & 0.6503 & 0.696 \\\\\n",
      "celltype_imr90-hmec-k562-kbm7_train.csv\n",
      "Overall & 0.9725 & 0.9624 & 0.96 \\\\\n",
      "celltype_imr90-hmec-k562-kbm7_val.csv\n",
      "Overall & 0.9593 & 0.9546 & 0.9341 \\\\\n"
     ]
    }
   ],
   "source": [
    "for exp in Path(\"../analytics/\").iterdir():\n",
    "    print(exp.name)\n",
    "    df = read_csv(exp)\n",
    "    accs = []\n",
    "    for model in [\"resnet\", \"lenet\", \"linear\"]:\n",
    "        accs.append(get_accuracy(df, None, model))\n",
    "    print(f\"Overall & {round(accs[0], 4)} & {round(accs[1], 4)} & {round(accs[2], 4)} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GM12878 & 28618\\\\\n",
      "IMR90 & 28610\\\\\n",
      "HMEC & 28520\\\\\n",
      "K562 & 28495\\\\\n",
      "KBM7 & 28751\\\\\n"
     ]
    }
   ],
   "source": [
    "all_train_df = read_csv(\"../analytics/all0_train.csv\")\n",
    "all_val_df = read_csv(\"../analytics/all0_val.csv\")\n",
    "all_test_df = read_csv(\"../analytics/all0_test.csv\")\n",
    "\n",
    "for cell_type in [\"GM12878\", \"IMR90\", \"HMEC\", \"K562\", \"KBM7\"]:\n",
    "    total = 0\n",
    "    for df in [all_train_df, all_val_df, all_test_df]:\n",
    "        total += len(df[df[\"cell_type\"] == cell_type])\n",
    "    print(f\"{cell_type} & {total}\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Path(\"C:/Users/alero/Documents/School/Spring23/Bio/Project/code/data/hic_dataset/GSM1551552_HIC003/1/0.199999.jpg\")\n",
    "im2 = Path(\"C:/Users/alero/Documents/School/Spring23/Bio/Project/code/data/hic_dataset/GSM1551552_HIC003/1/200000.399999.jpg\")\n",
    "im3 = Path(\"C:/Users/alero/Documents/School/Spring23/Bio/Project/code/data/hic_dataset/GSM1551552_HIC003/1/400000.599999.jpg\")\n",
    "im4 = Path(\"C:/Users/alero/Documents/School/Spring23/Bio/Project/code/data/hic_dataset/GSM1551552_HIC003/1/600000.799999.jpg\")\n",
    "im5 = Path(\"C:/Users/alero/Documents/School/Spring23/Bio/Project/code/data/hic_dataset/GSM1551552_HIC003/1/800000.999999.jpg\")\n",
    "im6 = Path(\"C:/Users/alero/Documents/School/Spring23/Bio/Project/code/data/hic_dataset/GSM1551552_HIC003/1/1000000.1199999.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the six images\n",
    "image1 = Image.open(im1).convert('L')\n",
    "image2 = Image.open(im2).convert('L')\n",
    "image3 = Image.open(im3).convert('L')\n",
    "image4 = Image.open(im4).convert('L')\n",
    "image5 = Image.open(im5).convert('L')\n",
    "image6 = Image.open(im6).convert('L')\n",
    "\n",
    "# Create a new figure and set the size and margins\n",
    "fig = plt.figure(figsize=(5, 7))\n",
    "fig.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.95, wspace=0.1, hspace=0.2)\n",
    "\n",
    "# Add the six images to the figure as subplots\n",
    "ax1 = fig.add_subplot(3, 2, 1)\n",
    "ax1.imshow(image1, cmap='gray')\n",
    "ax2 = fig.add_subplot(3, 2, 2)\n",
    "ax2.imshow(image2, cmap='gray')\n",
    "ax3 = fig.add_subplot(3, 2, 3)\n",
    "ax3.imshow(image3, cmap='gray')\n",
    "ax4 = fig.add_subplot(3, 2, 4)\n",
    "ax4.imshow(image4, cmap='gray')\n",
    "ax5 = fig.add_subplot(3, 2, 5)\n",
    "ax5.imshow(image5, cmap='gray')\n",
    "ax6 = fig.add_subplot(3, 2, 6)\n",
    "ax6.imshow(image6, cmap='gray')\n",
    "\n",
    "# Remove the axis labels\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "ax3.axis('off')\n",
    "ax4.axis('off')\n",
    "ax5.axis('off')\n",
    "ax6.axis('off')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
